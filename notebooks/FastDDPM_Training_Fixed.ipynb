{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5fd47eb",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6cd8f",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path and import data generator\n",
    "sys.path.insert(0, '../src')\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "CHECKPOINT_DIR = '../models'\n",
    "results_dir = '../results'\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = build_dataloader(split='train', batch_size=BATCH_SIZE, augment=True, num_workers=NUM_WORKERS)\n",
    "val_loader = build_dataloader(split='val', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "test_loader = build_dataloader(split='test', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"âœ… Data loaded: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")\n",
    "\n",
    "# Check one batch\n",
    "(pre_sample, post_sample), target_sample = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  pre: {pre_sample.shape}\")\n",
    "print(f\"  post: {post_sample.shape}\")\n",
    "print(f\"  target: {target_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d0d47",
   "metadata": {},
   "source": [
    "## 3. Noise Schedule (DDPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler:\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform'):\n",
    "        \n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.scheduler_type = scheduler_type\n",
    "        \n",
    "        # Pre-compute noise schedule (same as standard DDPM)\n",
    "        betas = torch.linspace(0.0001, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1 - alphas_cumprod))\n",
    "        \n",
    "        # Select timesteps based on strategy\n",
    "        if scheduler_type == 'uniform':\n",
    "            # Uniform spacing: every skip-th timestep\n",
    "            skip = num_timesteps // num_inference_steps\n",
    "            self.timesteps = torch.arange(0, num_timesteps, skip).long()[:num_inference_steps]\n",
    "        \n",
    "        elif scheduler_type == 'non-uniform':\n",
    "            # Non-uniform: concentrate in noisy region\n",
    "            if num_inference_steps == 10:\n",
    "                # Exact from paper: [0, 199, 399, 599, 699, 799, 849, 899, 949, 999]\n",
    "                self.timesteps = torch.tensor([0, 199, 399, 599, 699, 799, 849, 899, 949, 999]).long()\n",
    "            else:\n",
    "                # Adaptive non-uniform for other step counts\n",
    "                num_stage1 = int(num_inference_steps * 0.4)\n",
    "                num_stage2 = int(num_inference_steps * 0.6)\n",
    "                \n",
    "                if num_stage1 > 0:\n",
    "                    stage1 = torch.linspace(0, 699, num_stage1 + 1)[:-1].ceil().long()\n",
    "                else:\n",
    "                    stage1 = torch.tensor([]).long()\n",
    "                \n",
    "                stage2 = torch.linspace(699, 999, num_stage2 + 1)[:-1].ceil().long()\n",
    "                self.timesteps = torch.cat([stage1, stage2])\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler_type: {scheduler_type}\")\n",
    "    \n",
    "    def register_buffer(self, name, tensor):\n",
    "        setattr(self, name, tensor)\n",
    "    \n",
    "    def add_noise(self, x0, t, noise):\n",
    "        \"\"\"Forward process: x_t = sqrt(alpha_t)*x0 + sqrt(1-alpha_t)*eps\"\"\"\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "print(f\"âœ… Scheduler created with type: 'non-uniform'\")\n",
    "print(f\"âœ… Inference steps: {scheduler.timesteps.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c58c5",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"Build sinusoidal embeddings (from DDPM paper)\"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "    \n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal timestep embedding with learned projection\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t):\n",
    "        if t.dim() == 0:\n",
    "            t = t.unsqueeze(0)\n",
    "        emb = get_timestep_embedding(t, self.dim)\n",
    "        return self.fc(emb)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual block with time conditioning\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, time_dim):\n",
    "        super().__init__()\n",
    "        ng_in = max(1, in_ch // 4)\n",
    "        ng_out = max(1, out_ch // 4)\n",
    "        \n",
    "        self.norm1 = nn.GroupNorm(ng_in, in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(ng_out, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        \n",
    "        self.time_fc = nn.Linear(time_dim, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = F.silu(self.norm1(x))\n",
    "        h = self.conv1(h)\n",
    "        h = h + self.time_fc(t_emb)[:, :, None, None]\n",
    "        h = F.silu(self.norm2(h))\n",
    "        h = self.conv2(h)\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class FastDDPM(nn.Module):\n",
    "    \"\"\"Fast DDPM UNet for conditional denoising\"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_ch=64, time_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_dim)\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ResBlock(base_ch, base_ch * 2, time_dim)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ResBlock(base_ch * 4, base_ch * 8, time_dim)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlock(base_ch * 8, base_ch * 8, time_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, 2)\n",
    "        self.dec3 = ResBlock(base_ch * 4 + base_ch * 8, base_ch * 4, time_dim)\n",
    "    \n",
    "        self.upconv2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, 2)\n",
    "        self.dec2 = ResBlock(base_ch * 2 + base_ch * 4, base_ch * 2, time_dim)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, 2)\n",
    "        self.dec1 = ResBlock(base_ch + base_ch * 2, base_ch, time_dim)\n",
    "        \n",
    "        ng_final = max(1, base_ch // 4)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(ng_final, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, out_ch, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_emb(t)\n",
    "        h = self.init_conv(x)\n",
    "        \n",
    "        e1 = self.enc1(h, t_emb)\n",
    "        h = self.pool1(e1)\n",
    "        e2 = self.enc2(h, t_emb)\n",
    "        h = self.pool2(e2)\n",
    "        e3 = self.enc3(h, t_emb)\n",
    "        h = self.pool3(e3)\n",
    "        \n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        \n",
    "        h = self.upconv3(h)\n",
    "        h = torch.cat([h, e3], dim=1)\n",
    "        h = self.dec3(h, t_emb)\n",
    "        \n",
    "        h = self.upconv2(h)\n",
    "        h = torch.cat([h, e2], dim=1)\n",
    "        h = self.dec2(h, t_emb)\n",
    "        \n",
    "        h = self.upconv1(h)\n",
    "        h = torch.cat([h, e1], dim=1)\n",
    "        h = self.dec1(h, t_emb)\n",
    "        \n",
    "        return self.final(h)\n",
    "\n",
    "model = FastDDPM(in_ch=3, out_ch=1, base_ch=64, time_dim=128).to(DEVICE)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"âœ… Model created with 3 input channels: {num_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b9725",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec646fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler_device = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "\n",
    "# Move all scheduler tensors to device\n",
    "scheduler_device.betas = scheduler_device.betas.to(DEVICE)\n",
    "scheduler_device.alphas = scheduler_device.alphas.to(DEVICE)\n",
    "scheduler_device.alphas_cumprod = scheduler_device.alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.sqrt_alphas_cumprod = scheduler_device.sqrt_alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.sqrt_one_minus_alphas_cumprod = scheduler_device.sqrt_one_minus_alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.timesteps = scheduler_device.timesteps.to(DEVICE)\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "print(\"âœ… Scheduler tensors moved to device\")\n",
    "\n",
    "# ========== Checkpoint Utilities ==========\n",
    "def get_latest_checkpoint(checkpoint_dir, prefix='fastddpm_checkpoint'):\n",
    "    \"\"\"Get the latest checkpoint file by epoch number\"\"\"\n",
    "    from pathlib import Path\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    checkpoint_files = list(checkpoint_dir.glob(f'{prefix}_*.pt'))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    \n",
    "    checkpoints_with_epochs = []\n",
    "    for ckpt in checkpoint_files:\n",
    "        try:\n",
    "            epoch = int(ckpt.stem.split('_')[-1])\n",
    "            checkpoints_with_epochs.append((epoch, ckpt))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    if not checkpoints_with_epochs:\n",
    "        return None\n",
    "    \n",
    "    latest_epoch, latest_ckpt = max(checkpoints_with_epochs, key=lambda x: x[0])\n",
    "    return latest_ckpt, latest_epoch\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    \"\"\"Load checkpoint and return starting epoch and training state\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    history = checkpoint.get('history', {'epoch': [], 'train_loss': [], 'val_loss': []})\n",
    "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "    \n",
    "    return start_epoch, history, best_loss\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path):\n",
    "    \"\"\"Save checkpoint\"\"\"\n",
    "    from datetime import datetime\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "        'best_loss': best_loss,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(\"âœ… Checkpoint utilities defined\")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "print(\"\\nðŸ” Checking for existing checkpoints...\")\n",
    "latest_ckpt_info = get_latest_checkpoint(CHECKPOINT_DIR, prefix='fastddpm_checkpoint')\n",
    "\n",
    "if latest_ckpt_info is not None:\n",
    "    latest_ckpt_path, latest_epoch = latest_ckpt_info\n",
    "    print(f\"ðŸ“‚ Found checkpoint: {latest_ckpt_path.name}\")\n",
    "    \n",
    "    start_epoch, history, best_loss = load_checkpoint(\n",
    "        model, optimizer, latest_ckpt_path, DEVICE\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Loaded checkpoint from epoch {latest_epoch}\")\n",
    "    print(f\"   Resuming training from epoch {start_epoch}\")\n",
    "    print(f\"   Best validation loss so far: {best_loss:.4f}\\n\")\n",
    "else:\n",
    "    print(\"ðŸ“­ No checkpoint found - starting fresh training\\n\")\n",
    "    start_epoch = 1\n",
    "    history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "    best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680f867",
   "metadata": {},
   "source": [
    "## 6. Training & Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (pre, post), target in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        pre = pre.to(DEVICE)\n",
    "        post = post.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        # Random timesteps for training\n",
    "        batch_size = pre.shape[0]\n",
    "        t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size // 2 + 1,), device=DEVICE)\n",
    "        t_idx = torch.cat([t_idx, len(scheduler_device.timesteps) - t_idx - 1], dim=0)[:batch_size]\n",
    "        t = scheduler_device.timesteps[t_idx]\n",
    "        \n",
    "        noise = torch.randn_like(target).to(DEVICE)\n",
    "        x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "        \n",
    "        x_input = torch.cat([pre, post, x_noisy], dim=1)\n",
    "        pred_noise = model(x_input, t)\n",
    "        \n",
    "        loss = criterion(pred_noise, noise)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        del pre, post, target, noise, x_noisy, x_input, pred_noise, loss, t, t_idx\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate():\n",
    "    \"\"\"Validation with FIXED timesteps for stable loss (FIX #1)\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (pre, post), target in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "            pre = pre.to(DEVICE)\n",
    "            post = post.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "            \n",
    "            batch_size = pre.shape[0]\n",
    "            # FIX: Use FIXED timesteps for validation (not random)\n",
    "            num_timesteps = len(scheduler_device.timesteps)\n",
    "            t_indices = torch.linspace(0, num_timesteps - 1, batch_size).long().to(DEVICE)\n",
    "            t = scheduler_device.timesteps[t_indices]\n",
    "            \n",
    "            noise = torch.randn_like(target).to(DEVICE)\n",
    "            x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "            \n",
    "            x_input = torch.cat([pre, post, x_noisy], dim=1)\n",
    "            pred_noise = model(x_input, t)\n",
    "            loss = criterion(pred_noise, noise)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            del pre, post, target, noise, x_noisy, x_input, pred_noise, loss, t, t_indices\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "print(\"âœ… Training & validation functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18134b3",
   "metadata": {},
   "source": [
    "## 7. Sampling (Reverse Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caa23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(pre, post, num_samples=1):\n",
    "    \"\"\"Generate samples using reverse diffusion with FIXED formula (FIX #2)\"\"\"\n",
    "    model.eval()\n",
    "    batch_size = pre.shape[0]\n",
    "    \n",
    "    generated = []\n",
    "    for _ in range(num_samples):\n",
    "        x_t = torch.randn(batch_size, 1, 256, 256, device=DEVICE, dtype=torch.float32)\n",
    "        \n",
    "        timesteps = scheduler_device.timesteps.tolist()\n",
    "        num_steps = len(timesteps)\n",
    "        \n",
    "        for step_idx in range(num_steps - 1, -1, -1):\n",
    "            t_value = timesteps[step_idx]\n",
    "            t_batch = torch.full((batch_size,), t_value, dtype=torch.long, device=DEVICE)\n",
    "            \n",
    "            x_input = torch.cat([pre.to(DEVICE), post.to(DEVICE), x_t], dim=1)\n",
    "            pred_noise = model(x_input, t_batch)\n",
    "            \n",
    "            # FIX: Use alphas_cumprod consistently (not alphas)\n",
    "            alpha_t = scheduler_device.alphas_cumprod[t_value]\n",
    "            alpha_t_prev = scheduler_device.alphas_cumprod[timesteps[step_idx - 1]] if step_idx > 0 else torch.tensor(1.0, device=DEVICE)\n",
    "            \n",
    "            # Posterior variance (DDPM formula)\n",
    "            beta_t = 1.0 - scheduler_device.alphas[t_value]\n",
    "            posterior_var = (1 - alpha_t_prev) / (1 - alpha_t) * beta_t\n",
    "            posterior_var = torch.clamp(posterior_var, min=1e-20)\n",
    "            \n",
    "            # Reverse step with corrected formula\n",
    "            x_t = (1.0 / torch.sqrt(alpha_t)) * (\n",
    "                x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * pred_noise\n",
    "            )\n",
    "            \n",
    "            if step_idx > 0:\n",
    "                noise = torch.randn_like(x_t, device=DEVICE)\n",
    "                x_t = x_t + torch.sqrt(posterior_var) * noise\n",
    "        \n",
    "        generated.append(x_t)\n",
    "    \n",
    "    # FIX: Keep channel dimension (B, 1, H, W) not (B, H, W)\n",
    "    samples_stacked = torch.stack(generated, dim=0)\n",
    "    return samples_stacked.mean(dim=0)\n",
    "\n",
    "print(\"âœ… Sampling function ready (with fixes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f9997",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ Starting Training Loop\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "best_loss = float('inf')\n",
    "start_epoch = 1\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" âœ… (best)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Save checkpoint after every epoch\n",
    "    checkpoint_path = f'{CHECKPOINT_DIR}/fastddpm_checkpoint_{epoch}.pt'\n",
    "    save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path)\n",
    "\n",
    "with open(f'{results_dir}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Training complete! Best val loss: {best_loss:.4f}\")\n",
    "print(f\"ðŸ“Š Final history saved to fastddpm_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15f481",
   "metadata": {},
   "source": [
    "## 9. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history['epoch'], history['train_loss'], 'o-', label='Train Loss', linewidth=2, markersize=4)\n",
    "plt.plot(history['epoch'], history['val_loss'], 's-', label='Val Loss', linewidth=2, markersize=4)\n",
    "\n",
    "best_val_loss = min(history['val_loss'])\n",
    "best_epoch = history['epoch'][history['val_loss'].index(best_val_loss)]\n",
    "plt.axhline(y=best_val_loss, color='g', linestyle='--', alpha=0.5, label=f'Best Val Loss: {best_val_loss:.4f} (Epoch {best_epoch})')\n",
    "plt.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('FastDDPM Training History (With Fixes)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/fastddpm_training.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Plot saved\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea5989",
   "metadata": {},
   "source": [
    "## 10. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49714e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/fastddpm_best.pt', map_location=DEVICE))\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "predictions = []\n",
    "targets_list = []\n",
    "\n",
    "print(\"Running evaluation on test set...\")\n",
    "for (pre, post), target in tqdm(test_loader, desc=\"Testing\"):\n",
    "    generated = sample(pre, post, num_samples=3)  # (B, 1, H, W)\n",
    "    predictions.append(generated.cpu())\n",
    "    targets_list.append(target.cpu())\n",
    "    \n",
    "    # FIX: Proper tensor shape handling\n",
    "    pred = generated.squeeze(1).cpu().numpy()  # (B, H, W)\n",
    "    gt = target.squeeze(1).cpu().numpy()       # (B, H, W)\n",
    "    \n",
    "    for i in range(len(gt)):\n",
    "        gt_norm = (gt[i] - gt[i].min()) / (gt[i].max() - gt[i].min() + 1e-8)\n",
    "        pred_norm = (pred[i] - pred[i].min()) / (pred[i].max() - pred[i].min() + 1e-8)\n",
    "        \n",
    "        ssim_scores.append(ssim(gt_norm, pred_norm, data_range=1.0))\n",
    "        psnr_scores.append(psnr(gt_norm, pred_norm, data_range=1.0))\n",
    "    \n",
    "    del generated, pred, gt, gt_norm, pred_norm\n",
    "    if DEVICE == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FastDDPM Test Set Performance (with fixes)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"SSIM: {np.mean(ssim_scores):.4f} Â± {np.std(ssim_scores):.4f}\")\n",
    "print(f\"PSNR: {np.mean(psnr_scores):.2f} Â± {np.std(psnr_scores):.2f} dB\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
