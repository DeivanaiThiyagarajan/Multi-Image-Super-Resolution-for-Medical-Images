{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324b8306",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccef1a4",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path and import data generator\n",
    "sys.path.insert(0, '../src')\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "CHECKPOINT_DIR = '../models'\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = build_dataloader(split='train', batch_size=BATCH_SIZE, augment=True, num_workers=NUM_WORKERS)\n",
    "val_loader = build_dataloader(split='val', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "test_loader = build_dataloader(split='test', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"‚úÖ Data loaded: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")\n",
    "\n",
    "# Check one batch\n",
    "(pre_sample, post_sample), target_sample = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  pre: {pre_sample.shape}\")\n",
    "print(f\"  post: {post_sample.shape}\")\n",
    "print(f\"  target: {target_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4a0fe",
   "metadata": {},
   "source": [
    "## 3. Noise Schedule (DDPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler:\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform'):\n",
    "        \n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.scheduler_type = scheduler_type\n",
    "        \n",
    "        # Pre-compute noise schedule (same as standard DDPM)\n",
    "        betas = torch.linspace(0.0001, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1 - alphas_cumprod))\n",
    "        \n",
    "        # Select timesteps based on strategy\n",
    "        if scheduler_type == 'uniform':\n",
    "            # Uniform spacing: every skip-th timestep\n",
    "            skip = num_timesteps // num_inference_steps\n",
    "            self.timesteps = torch.arange(0, num_timesteps, skip).long()[:num_inference_steps]\n",
    "        \n",
    "        elif scheduler_type == 'non-uniform':\n",
    "            # Non-uniform: concentrate in noisy region\n",
    "            if num_inference_steps == 10:\n",
    "                # Exact from paper: [0, 199, 399, 599, 699, 799, 849, 899, 949, 999]\n",
    "                self.timesteps = torch.tensor([0, 199, 399, 599, 699, 799, 849, 899, 949, 999]).long()\n",
    "            else:\n",
    "                # Adaptive non-uniform for other step counts\n",
    "                # 40% in early stage (0-699), 60% in late stage (699-999)\n",
    "                num_stage1 = int(num_inference_steps * 0.4)\n",
    "                num_stage2 = int(num_inference_steps * 0.6)\n",
    "                \n",
    "                if num_stage1 > 0:\n",
    "                    stage1 = torch.linspace(0, 699, num_stage1 + 1)[:-1].ceil().long()\n",
    "                else:\n",
    "                    stage1 = torch.tensor([]).long()\n",
    "                \n",
    "                stage2 = torch.linspace(699, 999, num_stage2 + 1)[:-1].ceil().long()\n",
    "                self.timesteps = torch.cat([stage1, stage2])\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler_type: {scheduler_type}\")\n",
    "    \n",
    "    def register_buffer(self, name, tensor):\n",
    "        setattr(self, name, tensor)\n",
    "    \n",
    "    def add_noise(self, x0, t, noise):\n",
    "        \"\"\"Forward process: x_t = sqrt(alpha_t)*x0 + sqrt(1-alpha_t)*eps\"\"\"\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "\n",
    "# Create scheduler (change to 'uniform' if preferred)\n",
    "scheduler = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "print(f\"‚úÖ Scheduler created with type: 'non-uniform'\")\n",
    "print(f\"‚úÖ Inference steps: {scheduler.timesteps.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f4b57",
   "metadata": {},
   "source": [
    "## 4. Model Architecture (with 3 input channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastDDPM(nn.Module):\n",
    "    \"\"\"Fast DDPM UNet for conditional denoising\"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_ch=64, time_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_dim)\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ResBlock(base_ch, base_ch * 2, time_dim)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ResBlock(base_ch * 4, base_ch * 8, time_dim)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlock(base_ch * 8, base_ch * 8, time_dim)\n",
    "        \n",
    "        # Decoder with correct channel dimensions for skip connections\n",
    "        # After upconv3: base_ch*4, concatenate with e3 (base_ch*8) -> base_ch*4 + base_ch*8 = base_ch*12\n",
    "        self.upconv3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, 2)\n",
    "        self.dec3 = ResBlock(base_ch * 4 + base_ch * 8, base_ch * 4, time_dim)  # in_ch = concatenated channels\n",
    "        \n",
    "        # After upconv2: base_ch*2, concatenate with e2 (base_ch*4) -> base_ch*2 + base_ch*4 = base_ch*6\n",
    "        self.upconv2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, 2)\n",
    "        self.dec2 = ResBlock(base_ch * 2 + base_ch * 4, base_ch * 2, time_dim)\n",
    "        \n",
    "        # After upconv1: base_ch, concatenate with e1 (base_ch*2) -> base_ch + base_ch*2 = base_ch*3\n",
    "        self.upconv1 = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, 2)\n",
    "        self.dec1 = ResBlock(base_ch + base_ch * 2, base_ch, time_dim)\n",
    "        \n",
    "        # Final output\n",
    "        ng_final = max(1, base_ch // 4)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(ng_final, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, out_ch, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_emb(t)\n",
    "        \n",
    "        # Initial conv\n",
    "        h = self.init_conv(x)\n",
    "        \n",
    "        # Encoder with skip connections\n",
    "        e1 = self.enc1(h, t_emb)\n",
    "        h = self.pool1(e1)\n",
    "        e2 = self.enc2(h, t_emb)\n",
    "        h = self.pool2(e2)\n",
    "        e3 = self.enc3(h, t_emb)\n",
    "        h = self.pool3(e3)\n",
    "        \n",
    "        # Bottleneck\n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        h = self.upconv3(h)\n",
    "        h = torch.cat([h, e3], dim=1)\n",
    "        h = self.dec3(h, t_emb)\n",
    "        \n",
    "        h = self.upconv2(h)\n",
    "        h = torch.cat([h, e2], dim=1)\n",
    "        h = self.dec2(h, t_emb)\n",
    "        \n",
    "        h = self.upconv1(h)\n",
    "        h = torch.cat([h, e1], dim=1)\n",
    "        h = self.dec1(h, t_emb)\n",
    "        \n",
    "        return self.final(h)\n",
    "\n",
    "# Create model with 3 input channels: [pre, post, noisy_target]\n",
    "model = FastDDPM(in_ch=3, out_ch=1, base_ch=64, time_dim=128).to(DEVICE)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ Model created with 3 input channels: {num_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c79af8",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Checkpoint Utilities ==========\n",
    "def get_latest_checkpoint(checkpoint_dir, prefix='fastddpm_checkpoint'):\n",
    "    \"\"\"Get the latest checkpoint file by epoch number\"\"\"\n",
    "    from pathlib import Path\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    checkpoint_files = list(checkpoint_dir.glob(f'{prefix}_*.pt'))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    \n",
    "    # Extract epoch numbers and sort\n",
    "    checkpoints_with_epochs = []\n",
    "    for ckpt in checkpoint_files:\n",
    "        try:\n",
    "            epoch = int(ckpt.stem.split('_')[-1])\n",
    "            checkpoints_with_epochs.append((epoch, ckpt))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    if not checkpoints_with_epochs:\n",
    "        return None\n",
    "    \n",
    "    # Return path of checkpoint with highest epoch\n",
    "    latest_epoch, latest_ckpt = max(checkpoints_with_epochs, key=lambda x: x[0])\n",
    "    return latest_ckpt, latest_epoch\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, checkpoint_path, device):\n",
    "    \"\"\"Load checkpoint and return starting epoch and training state\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    history = checkpoint.get('history', {'epoch': [], 'train_loss': [], 'val_loss': []})\n",
    "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "    \n",
    "    return start_epoch, history, best_loss, checkpoint\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path):\n",
    "    \"\"\"Save checkpoint\"\"\"\n",
    "    from datetime import datetime\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "        'best_loss': best_loss,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(\"‚úÖ Checkpoint utilities defined\")\n",
    "\n",
    "# ========== Setup training with checkpoint support ==========\n",
    "# Check for existing checkpoint\n",
    "print(\"\\nüîç Checking for existing checkpoints...\")\n",
    "latest_ckpt_info = get_latest_checkpoint(CHECKPOINT_DIR, prefix='fastddpm_checkpoint')\n",
    "\n",
    "if latest_ckpt_info is not None:\n",
    "    latest_ckpt_path, latest_epoch = latest_ckpt_info\n",
    "    print(f\"üìÇ Found checkpoint: {latest_ckpt_path.name}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    start_epoch, history, best_loss, loaded_ckpt = load_checkpoint(\n",
    "        model, optimizer, scheduler_device, latest_ckpt_path, DEVICE\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Loaded checkpoint from epoch {latest_epoch}\")\n",
    "    print(f\"   Resuming training from epoch {start_epoch}\")\n",
    "    print(f\"   Best validation loss so far: {best_loss:.4f}\")\n",
    "    print(f\"   Epochs completed: {latest_epoch}\\n\")\n",
    "else:\n",
    "    print(\"üì≠ No checkpoint found - starting fresh training\\n\")\n",
    "    start_epoch = 1\n",
    "    history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "    best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a34e6",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Training Loop with Checkpoint Support ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Starting Training Loop\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    # Update best loss and save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" ‚úÖ (best)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Save checkpoint after every epoch\n",
    "    checkpoint_path = f'{CHECKPOINT_DIR}/fastddpm_checkpoint_{epoch}.pt'\n",
    "    save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path)\n",
    "\n",
    "# Save final history\n",
    "with open(f'{CHECKPOINT_DIR}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete! Best val loss: {best_loss:.4f}\")\n",
    "print(f\"üìä Final history saved to fastddpm_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883f433",
   "metadata": {},
   "source": [
    "## 7. Sampling (Reverse Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(pre, post, num_samples=1):\n",
    "    \"\"\"Generate samples using reverse diffusion\"\"\"\n",
    "    model.eval()\n",
    "    batch_size = pre.shape[0]\n",
    "    \n",
    "    generated = []\n",
    "    for _ in range(num_samples):\n",
    "        # Start with random noise for the target\n",
    "        x_t = torch.randn(batch_size, 1, 256, 256, device=DEVICE, dtype=torch.float32)\n",
    "        \n",
    "        # Reverse process (denoising)\n",
    "        for step_idx, t_idx in enumerate(reversed(range(len(scheduler_device.timesteps)))):\n",
    "            t = scheduler_device.timesteps[t_idx]\n",
    "            t_batch = t.unsqueeze(0).expand(batch_size)\n",
    "            \n",
    "            # Concatenate: [clean_pre, clean_post, current_noisy_target]\n",
    "            x_input = torch.cat([pre.to(DEVICE), post.to(DEVICE), x_t], dim=1)  # (B, 3, H, W)\n",
    "            \n",
    "            # Predict noise at this timestep\n",
    "            pred_noise = model(x_input, t_batch)\n",
    "            \n",
    "            # Reverse step - ensure all tensors on DEVICE\n",
    "            alpha_t = scheduler_device.alphas_cumprod[t]\n",
    "            if t_idx > 0:\n",
    "                t_prev_idx = scheduler_device.timesteps[t_idx - 1]\n",
    "                alpha_prev = scheduler_device.alphas_cumprod[t_prev_idx]\n",
    "            else:\n",
    "                alpha_prev = torch.tensor(1.0, device=DEVICE, dtype=torch.float32)\n",
    "            \n",
    "            # Posterior variance\n",
    "            posterior_var = (1 - alpha_prev) / (1 - alpha_t) * (1 - alpha_t / alpha_prev)\n",
    "            posterior_var = torch.clamp(posterior_var, min=1e-20)\n",
    "            \n",
    "            noise = torch.randn_like(x_t, device=DEVICE) if t_idx > 0 else torch.zeros_like(x_t)\n",
    "            \n",
    "            # Denoising step\n",
    "            x_t = (1.0 / torch.sqrt(alpha_t)) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * pred_noise) + torch.sqrt(posterior_var) * noise\n",
    "        \n",
    "        generated.append(x_t.cpu())\n",
    "    \n",
    "    return torch.stack(generated, dim=1)\n",
    "\n",
    "print(\"‚úÖ Sampling function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f8946",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b97910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/fastddpm_best.pt'))\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for (pre, post), target in tqdm(test_loader, desc=\"Testing\"):\n",
    "    generated = sample(pre, post, num_samples=3)\n",
    "    pred = generated.mean(dim=1).squeeze().numpy()\n",
    "    gt = target.squeeze().numpy()\n",
    "    \n",
    "    for i in range(len(gt)):\n",
    "        gt_norm = (gt[i] - gt[i].min()) / (gt[i].max() - gt[i].min() + 1e-8)\n",
    "        pred_norm = (pred[i] - pred[i].min()) / (pred[i].max() - pred[i].min() + 1e-8)\n",
    "        \n",
    "        ssim_scores.append(ssim(gt_norm, pred_norm, data_range=1.0))\n",
    "        psnr_scores.append(psnr(gt_norm, pred_norm, data_range=1.0))\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"SSIM: {np.mean(ssim_scores):.4f} ¬± {np.std(ssim_scores):.4f}\")\n",
    "print(f\"PSNR: {np.mean(psnr_scores):.2f} ¬± {np.std(psnr_scores):.2f} dB\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9af89",
   "metadata": {},
   "source": [
    "## 9. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['epoch'], history['train_loss'], 'o-', label='Train Loss', linewidth=2)\n",
    "plt.plot(history['epoch'], history['val_loss'], 's-', label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Fast-DDPM Training History', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHECKPOINT_DIR}/fastddpm_training.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Plot saved to {CHECKPOINT_DIR}/fastddpm_training.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
