{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a62dd4",
   "metadata": {},
   "source": [
    "# Fast-DDPM Training with Segregated Metrics for Multi-Image Super-Resolution\n",
    "\n",
    "This notebook demonstrates Fast-DDPM training using ModelDataGenerator_1.py dataloaders with distance filtering for segregated metric evaluation (3mm gap: distance 2, and 6mm gap: distance 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9429ba36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "GPU: NVIDIA B200\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "# Import data generator\n",
    "from ModelDataGenerator_1 import build_dataloader\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cdadde",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe48ed35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Parameters:\n",
      "  device: cuda\n",
      "  batch_size: 4\n",
      "  num_workers: 4\n",
      "  pin_memory: True\n",
      "  num_epochs: 20\n",
      "  learning_rate: 0.0001\n",
      "  weight_decay: 0.0\n",
      "  gradient_clip: 1.0\n",
      "  image_size: 256\n",
      "  in_channels: 2\n",
      "  out_channels: 1\n",
      "  num_timesteps: 1000\n",
      "  fast_ddpm_steps: 10\n",
      "  beta_schedule: linear\n",
      "  beta_start: 0.0001\n",
      "  beta_end: 0.02\n",
      "  scheduler_type: uniform\n",
      "  sample_type: generalized\n",
      "  optimizer: adam\n",
      "  eps: 1e-08\n",
      "  ckpt_freq: 5\n",
      "  early_stopping_patience: 5\n",
      "  model_dir: ../models/fast_ddpm_v3\n",
      "  results_file: ../results/fastddpm_v3_history.json\n"
     ]
    }
   ],
   "source": [
    "# Configuration Parameters\n",
    "CONFIG = {\n",
    "    # Device\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Dataset\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    \n",
    "    # Training\n",
    "    'num_epochs': 20,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'gradient_clip': 1.0,\n",
    "    \n",
    "    # Diffusion Model\n",
    "    'image_size': 256,\n",
    "    'in_channels': 2,  # Two input images (pre and post)\n",
    "    'out_channels': 1,  # One output image (middle/target)\n",
    "    'num_timesteps': 1000,  # Total diffusion steps\n",
    "    'fast_ddpm_steps': 10,  # Fast-DDPM uses 10 steps\n",
    "    'beta_schedule': 'linear',\n",
    "    'beta_start': 0.0001,\n",
    "    'beta_end': 0.02,\n",
    "    \n",
    "    # Scheduler\n",
    "    'scheduler_type': 'uniform',  # 'uniform' or 'non-uniform'\n",
    "    'sample_type': 'generalized',\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': 'adam',\n",
    "    'eps': 1e-8,\n",
    "    \n",
    "    # Checkpointing\n",
    "    'ckpt_freq': 5,\n",
    "    'early_stopping_patience': 5,\n",
    "    \n",
    "    # Results\n",
    "    'model_dir': '../models/fast_ddpm_v3',\n",
    "    'results_file': '../results/fastddpm_v3_history.json'\n",
    "}\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs(CONFIG['model_dir'], exist_ok=True)\n",
    "os.makedirs(os.path.dirname(CONFIG['results_file']), exist_ok=True)\n",
    "\n",
    "print(\"Configuration Parameters:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ff2af",
   "metadata": {},
   "source": [
    "## 3. Fast-DDPM Model Implementation\n",
    "\n",
    "Based on mirthAI/Fast-DDPM repository architecture for super-resolution tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85c3369c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast-DDPM Model classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"Get sinusoidal timestep embeddings\"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "    \n",
    "    half_dim = embedding_dim // 2\n",
    "    # Avoid division by zero when half_dim = 1\n",
    "    emb = np.log(10000) / max(half_dim - 1, 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(timesteps.device)\n",
    "    emb = timesteps[:, None].float() * emb[None, :]\n",
    "    \n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n",
    "    \n",
    "    return emb\n",
    "\n",
    "def nonlinearity(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "def get_norm(in_channels, num_groups=32):\n",
    "    \"\"\"Get GroupNorm with adaptive num_groups if needed\"\"\"\n",
    "    if in_channels % num_groups == 0:\n",
    "        return nn.GroupNorm(num_groups, in_channels)\n",
    "    for groups in [16, 8, 4, 2, 1]:\n",
    "        if in_channels % groups == 0:\n",
    "            return nn.GroupNorm(groups, in_channels)\n",
    "    return nn.BatchNorm2d(in_channels)\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        return self.conv(x)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, temb_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.norm1 = get_norm(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.temb_proj = nn.Linear(temb_dim, out_channels)\n",
    "        \n",
    "        self.norm2 = get_norm(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, temb):\n",
    "        h = nonlinearity(self.norm1(x))\n",
    "        h = self.conv1(h)\n",
    "        h += self.temb_proj(nonlinearity(temb))[:, :, None, None]\n",
    "        h = nonlinearity(self.norm2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.norm = get_norm(in_channels)\n",
    "        self.q = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.k = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.v = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.proj_out = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.norm(x)\n",
    "        q = self.q(h)\n",
    "        k = self.k(h)\n",
    "        v = self.v(h)\n",
    "        \n",
    "        q = q.reshape(B, C, -1)\n",
    "        k = k.reshape(B, C, -1)\n",
    "        v = v.reshape(B, C, -1)\n",
    "        \n",
    "        attn = torch.bmm(q.transpose(1, 2), k)\n",
    "        attn = attn / np.sqrt(C)\n",
    "        attn = torch.nn.functional.softmax(attn, dim=-1)\n",
    "        \n",
    "        out = torch.bmm(v, attn.transpose(1, 2))\n",
    "        out = out.reshape(B, C, H, W)\n",
    "        out = self.proj_out(out)\n",
    "        \n",
    "        return out + x\n",
    "\n",
    "class FastDDPMSRModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        ch = config['in_channels']  # Use in_channels directly (2 for pre + post)\n",
    "        out_ch = config['out_channels']\n",
    "        num_res_blocks = 2\n",
    "        ch_mult = (1, 2, 4)\n",
    "        num_resolutions = len(ch_mult)\n",
    "        attn_resolutions = (8,)\n",
    "        dropout = 0.1\n",
    "        \n",
    "        self.ch = ch\n",
    "        self.num_resolutions = num_resolutions\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        \n",
    "        # Timestep embedding\n",
    "        self.temb_ch = ch * 4\n",
    "        self.temb_dense = nn.Sequential(\n",
    "            nn.Linear(ch, self.temb_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.temb_ch, self.temb_ch)\n",
    "        )\n",
    "        \n",
    "        # Input conv\n",
    "        self.conv_in = nn.Conv2d(ch, ch, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        cur_ch = ch\n",
    "        for i in range(num_resolutions):\n",
    "            res_blocks = nn.ModuleList()\n",
    "            attn_blocks = nn.ModuleList()\n",
    "            \n",
    "            out_ch_mult = ch * ch_mult[i]\n",
    "            for _ in range(num_res_blocks):\n",
    "                res_blocks.append(ResnetBlock(cur_ch, out_ch_mult, self.temb_ch, dropout))\n",
    "                if out_ch_mult in attn_resolutions:\n",
    "                    attn_blocks.append(AttnBlock(out_ch_mult))\n",
    "                cur_ch = out_ch_mult\n",
    "            \n",
    "            down_block = nn.Module()\n",
    "            down_block.res_blocks = res_blocks\n",
    "            down_block.attn_blocks = attn_blocks\n",
    "            self.down_blocks.append(down_block)\n",
    "            \n",
    "            if i != num_resolutions - 1:\n",
    "                self.down_blocks.append(Downsample(cur_ch))\n",
    "        \n",
    "        # Middle blocks\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(cur_ch, cur_ch, self.temb_ch, dropout)\n",
    "        self.mid.attn = AttnBlock(cur_ch)\n",
    "        self.mid.block_2 = ResnetBlock(cur_ch, cur_ch, self.temb_ch, dropout)\n",
    "        \n",
    "        # Upsampling (simplified - no skip connections for now)\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in reversed(range(num_resolutions)):\n",
    "            out_ch_mult = ch * ch_mult[i]\n",
    "            \n",
    "            res_blocks = nn.ModuleList()\n",
    "            attn_blocks = nn.ModuleList()\n",
    "            \n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                res_blocks.append(ResnetBlock(cur_ch, out_ch_mult, self.temb_ch, dropout))\n",
    "                if out_ch_mult in attn_resolutions:\n",
    "                    attn_blocks.append(AttnBlock(out_ch_mult))\n",
    "                cur_ch = out_ch_mult\n",
    "            \n",
    "            up_block = nn.Module()\n",
    "            up_block.res_blocks = res_blocks\n",
    "            up_block.attn_blocks = attn_blocks\n",
    "            self.up_blocks.append(up_block)\n",
    "            \n",
    "            if i != 0:\n",
    "                self.up_blocks.append(Upsample(cur_ch))\n",
    "        \n",
    "        # Output\n",
    "        self.norm_out = get_norm(cur_ch)\n",
    "        self.conv_out = nn.Conv2d(cur_ch, out_ch, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, 2, H, W) - concatenated input and reference images\n",
    "            t: (B,) - timestep indices\n",
    "        Returns:\n",
    "            output: (B, 1, H, W) - predicted noise\n",
    "        \"\"\"\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = self.temb_dense(temb)\n",
    "        \n",
    "        h = self.conv_in(x)\n",
    "        \n",
    "        # Downsampling\n",
    "        for block in self.down_blocks:\n",
    "            if isinstance(block, Downsample):\n",
    "                h = block(h)\n",
    "            else:\n",
    "                for j, res_block in enumerate(block.res_blocks):\n",
    "                    h = res_block(h, temb)\n",
    "                    if j < len(block.attn_blocks):\n",
    "                        h = block.attn_blocks[j](h)\n",
    "        \n",
    "        # Middle\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "        \n",
    "        # Upsampling\n",
    "        for block in self.up_blocks:\n",
    "            if isinstance(block, Upsample):\n",
    "                h = block(h)\n",
    "            else:\n",
    "                # This is the ResBlock container\n",
    "                for i, res_block in enumerate(block.res_blocks):\n",
    "                    h = res_block(h, temb)\n",
    "                    if i < len(block.attn_blocks):\n",
    "                        h = block.attn_blocks[i](h)\n",
    "        \n",
    "        # Output\n",
    "        h = nonlinearity(self.norm_out(h))\n",
    "        h = self.conv_out(h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "print(\"Fast-DDPM Model classes defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c417817",
   "metadata": {},
   "source": [
    "## 4. Diffusion Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a92afeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion schedule initialized with 1000 timesteps\n",
      "Beta range: [0.0001, 0.02]\n"
     ]
    }
   ],
   "source": [
    "def get_beta_schedule(beta_schedule, beta_start, beta_end, num_diffusion_timesteps):\n",
    "    \"\"\"Get beta schedule for diffusion process\"\"\"\n",
    "    if beta_schedule == \"quad\":\n",
    "        betas = np.linspace(beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps) ** 2\n",
    "    elif beta_schedule == \"linear\":\n",
    "        betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps)\n",
    "    elif beta_schedule == \"cosine\":\n",
    "        s = 0.008\n",
    "        steps = np.arange(0, num_diffusion_timesteps + 1, dtype=np.float64) / num_diffusion_timesteps\n",
    "        alphas_cumprod = np.cos(((steps + s) / (1 + s)) * np.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        betas = np.clip(betas, a_min=0, a_max=0.9999)\n",
    "    else:\n",
    "        raise ValueError(f\"unknown beta schedule: {beta_schedule}\")\n",
    "    \n",
    "    return torch.from_numpy(betas).float()\n",
    "\n",
    "class DiffusionSchedule:\n",
    "    def __init__(self, betas):\n",
    "        \"\"\"Initialize diffusion schedule from betas\"\"\"\n",
    "        self.betas = betas\n",
    "        self.num_timesteps = len(betas)\n",
    "        self.device = betas.device\n",
    "        \n",
    "        alphas = 1 - betas\n",
    "        self.alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.ones(1, device=self.device), self.alphas_cumprod[:-1]])\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.rsqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recip_m1_alphas_cumprod = torch.sqrt(1 / self.alphas_cumprod - 1)\n",
    "        \n",
    "        posterior_variance = (\n",
    "            betas * (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_variance = posterior_variance\n",
    "        self.posterior_log_variance_clipped = torch.log(torch.clamp(posterior_variance, min=1e-20))\n",
    "        self.posterior_mean_coef1 = betas * torch.sqrt(self.alphas_cumprod_prev) / (1 - self.alphas_cumprod)\n",
    "        self.posterior_mean_coef2 = (1 - self.alphas_cumprod_prev) * torch.sqrt(alphas) / (1 - self.alphas_cumprod)\n",
    "    \n",
    "    def compute_alpha(self, t):\n",
    "        \"\"\"Get alpha value for timestep t\"\"\"\n",
    "        return self.alphas_cumprod[t]\n",
    "    \n",
    "    def get_sampler_schedule(self, timesteps, scheduler_type='uniform'):\n",
    "        \"\"\"Get sampling schedule for Fast-DDPM\"\"\"\n",
    "        if scheduler_type == 'uniform':\n",
    "            skip = self.num_timesteps // timesteps\n",
    "            seq = list(range(0, self.num_timesteps, skip))\n",
    "            if seq[-1] != self.num_timesteps - 1:\n",
    "                seq.append(self.num_timesteps - 1)\n",
    "            return seq\n",
    "        elif scheduler_type == 'non-uniform':\n",
    "            # Non-uniform schedule from Fast-DDPM paper\n",
    "            seq = [0, 199, 399, 599, 699, 799, 849, 899, 949, 999]\n",
    "            if timesteps != 10:\n",
    "                num_1 = int(timesteps * 0.4)\n",
    "                num_2 = int(timesteps * 0.6)\n",
    "                stage_1 = np.linspace(0, 699, num_1 + 1)[:-1]\n",
    "                stage_2 = np.linspace(699, 999, num_2)\n",
    "                seq = np.concatenate([stage_1, stage_2]).astype(int).tolist()\n",
    "            return seq\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")\n",
    "\n",
    "# Initialize diffusion schedule\n",
    "betas = get_beta_schedule(\n",
    "    CONFIG['beta_schedule'],\n",
    "    CONFIG['beta_start'],\n",
    "    CONFIG['beta_end'],\n",
    "    CONFIG['num_timesteps']\n",
    ")\n",
    "# Create on CPU first, then move to device\n",
    "diffusion_schedule = DiffusionSchedule(betas.to(CONFIG['device']))\n",
    "\n",
    "print(f\"Diffusion schedule initialized with {CONFIG['num_timesteps']} timesteps\")\n",
    "print(f\"Beta range: [{CONFIG['beta_start']}, {CONFIG['beta_end']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08b9ea",
   "metadata": {},
   "source": [
    "## 5. Initialize Dataloaders with Distance Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c606e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 641 volumes in RAM\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 113 volumes in RAM\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 160 volumes in RAM\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 160 volumes in RAM\n",
      "Train loader: 18269 batches\n",
      "Validation loader: 3221 batches\n",
      "Test loader (distance 2 - 3mm gap): 2320 batches\n",
      "Test loader (distance 4 - 6mm gap): 2240 batches\n",
      "\n",
      "Sample batch shapes:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m sample = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample batch shapes:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  pre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpre\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  post: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Build dataloaders with distance filtering\n",
    "# distance_filter=None: all triplets (mixed distance 2 and 4)\n",
    "# distance_filter=2: only (i, i+2)->i+1 pairs [3mm gap, 1.5mm interpolation]\n",
    "# distance_filter=4: only (i, i+4)->i+2 pairs [6mm gap, 3mm interpolation]\n",
    "\n",
    "train_loader = build_dataloader(\n",
    "    split='train',\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    #pin_memory=CONFIG['pin_memory'],\n",
    "    distance_filter=None,  # Use all triplets for training\n",
    "    #shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = build_dataloader(\n",
    "    split = 'val',\n",
    "    batch_size = CONFIG['batch_size'],\n",
    "    num_workers = CONFIG['num_workers'],\n",
    "    #pin_memory = CONFIG['pin_memeory'],\n",
    "    distance_filter = None,\n",
    "    #shuffle = True\n",
    ")\n",
    "\n",
    "# Test loaders separated by distance\n",
    "test_loader_dist2 = build_dataloader(\n",
    "    split='test',\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    #pin_memory=CONFIG['pin_memory'],\n",
    "    distance_filter=2,  # Only 3mm gaps\n",
    "    #shuffle=False\n",
    ")\n",
    "\n",
    "test_loader_dist4 = build_dataloader(\n",
    "    split='test',\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    #pin_memory=CONFIG['pin_memory'],\n",
    "    distance_filter=4,  # Only 6mm gaps\n",
    "    #shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Validation loader: {len(val_loader)} batches\")\n",
    "print(f\"Test loader (distance 2 - 3mm gap): {len(test_loader_dist2)} batches\")\n",
    "print(f\"Test loader (distance 4 - 6mm gap): {len(test_loader_dist4)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a501657-2afa-4ba3-9210-e16ec989c152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample batch shapes:\n",
      "  pre: torch.Size([4, 1, 256, 256])\n",
      "  post: torch.Size([4, 1, 256, 256])\n",
      "  target: torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inspect a batch\n",
    "(pre, post), middle = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  pre: {pre.shape}\")\n",
    "print(f\"  post: {post.shape}\")\n",
    "print(f\"  target: {middle.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582c397",
   "metadata": {},
   "source": [
    "## 6. Model, Optimizer, and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c199c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 13,971\n",
      "Trainable Parameters: 13,971\n",
      "Optimizer: Adam (lr=0.0001)\n",
      "Loss: MSELoss\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = FastDDPMSRModel(CONFIG)\n",
    "model = model.to(CONFIG['device'])\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=CONFIG['eps'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    #verbose=True\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"Optimizer: Adam (lr={CONFIG['learning_rate']})\")\n",
    "print(f\"Loss: MSELoss\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13b4bf",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b58074c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, diffusion_schedule, device, config):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for (pre_1, post_1), middle_1 in pbar:\n",
    "        pre = pre_1.to(device).float()      # (B, 1, H, W)\n",
    "        post = post_1.to(device).float()    # (B, 1, H, W)\n",
    "        target = middle_1.to(device).float()  # (B, 1, H, W)\n",
    "        \n",
    "        # Concatenate pre and post as input\n",
    "        x_input = torch.cat([pre, post], dim=1)  # (B, 2, H, W)\n",
    "        \n",
    "        # Sample random timesteps (antithetic sampling)\n",
    "        batch_size = x_input.size(0)\n",
    "        half_batch = batch_size // 2 + 1\n",
    "        \n",
    "        if config['scheduler_type'] == 'uniform':\n",
    "            t_rand = torch.randint(0, config['num_timesteps'], (half_batch,), device=device)\n",
    "            t = torch.cat([t_rand, config['num_timesteps'] - t_rand - 1], dim=0)[:batch_size]\n",
    "        else:\n",
    "            # Non-uniform sampling\n",
    "            t_rand = torch.randint(0, config['num_timesteps'], (batch_size,), device=device)\n",
    "            t = t_rand\n",
    "        \n",
    "        t = t.long()\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn_like(target)\n",
    "        \n",
    "        # Forward diffusion process: q(x_t | x_0) = sqrt(alpha_t) * x_0 + sqrt(1 - alpha_t) * epsilon\n",
    "        alpha_t = diffusion_schedule.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        std_t = diffusion_schedule.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        \n",
    "        x_t = alpha_t * target + std_t * noise\n",
    "        \n",
    "        # Predict noise\n",
    "        optimizer.zero_grad()\n",
    "        noise_pred = model(x_input, t.float())\n",
    "        \n",
    "        # MSE loss on noise prediction\n",
    "        loss = criterion(noise_pred, noise)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        if config['gradient_clip'] > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Clean up intermediate variables and clear cache\n",
    "        del pre, post, target, x_input, t_rand, t, noise, alpha_t, std_t, x_t, noise_pred, loss\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, test_loader, criterion, diffusion_schedule, device, config):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Evaluating\", leave=False)\n",
    "        for (pre_1, post_1), middle_1 in pbar:\n",
    "            pre = pre_1.to(device).float()\n",
    "            post = post_1.to(device).float()\n",
    "            target = middle_1.to(device).float()\n",
    "            \n",
    "            # Concatenate pre and post as input\n",
    "            x_input = torch.cat([pre, post], dim=1)\n",
    "            \n",
    "            batch_size = x_input.size(0)\n",
    "            \n",
    "            # Sample timesteps uniformly for evaluation\n",
    "            t = torch.randint(0, config['num_timesteps'], (batch_size,), device=device).long()\n",
    "            \n",
    "            # Sample noise\n",
    "            noise = torch.randn_like(target)\n",
    "            \n",
    "            # Forward diffusion process\n",
    "            alpha_t = diffusion_schedule.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "            std_t = diffusion_schedule.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "            \n",
    "            x_t = alpha_t * target + std_t * noise\n",
    "            \n",
    "            # Predict noise\n",
    "            noise_pred = model(x_input, t.float())\n",
    "            \n",
    "            # MSE loss\n",
    "            loss = criterion(noise_pred, noise)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Denoise to get prediction of target\n",
    "            predicted_target = (x_t - std_t * noise_pred) / alpha_t\n",
    "            predicted_target = torch.clamp(predicted_target, -1, 1)\n",
    "            \n",
    "            all_predictions.append(predicted_target.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "            \n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            # Clean up intermediate variables and clear cache\n",
    "            del pre, post, target, x_input, t, noise, alpha_t, std_t, x_t, noise_pred, loss, predicted_target\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    predictions = torch.cat(all_predictions, dim=0).numpy()\n",
    "    targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    \n",
    "    return avg_loss, predictions, targets\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4fb510",
   "metadata": {},
   "source": [
    "## 8. Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c66b87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics_for_predictions(predictions, targets):\n",
    "    \"\"\"\n",
    "    Compute SSIM and PSNR metrics\n",
    "    \n",
    "    Args:\n",
    "        predictions: (N, 1, H, W) normalized predictions\n",
    "        targets: (N, 1, H, W) normalized targets\n",
    "    Returns:\n",
    "        dict with SSIM and PSNR statistics\n",
    "    \"\"\"\n",
    "    # Denormalize from [-1, 1] to [0, 1]\n",
    "    predictions = (predictions + 1) / 2\n",
    "    targets = (targets + 1) / 2\n",
    "    \n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    \n",
    "    for pred, targ in zip(predictions, targets):\n",
    "        # Remove channel dimension if present\n",
    "        if pred.ndim == 3:\n",
    "            pred = pred[0]\n",
    "        if targ.ndim == 3:\n",
    "            targ = targ[0]\n",
    "        \n",
    "        pred_np = np.clip(pred, 0, 1)\n",
    "        targ_np = np.clip(targ, 0, 1)\n",
    "        \n",
    "        # SSIM\n",
    "        ssim_val = ssim(targ_np, pred_np, data_range=1.0)\n",
    "        ssim_scores.append(ssim_val)\n",
    "        \n",
    "        # PSNR\n",
    "        mse = np.mean((targ_np - pred_np) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr_val = 100\n",
    "        else:\n",
    "            psnr_val = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "        psnr_scores.append(psnr_val)\n",
    "    \n",
    "    ssim_scores = np.array(ssim_scores)\n",
    "    psnr_scores = np.array(psnr_scores)\n",
    "    \n",
    "    metrics = {\n",
    "        'ssim': {\n",
    "            'mean': float(np.mean(ssim_scores)),\n",
    "            'std': float(np.std(ssim_scores)),\n",
    "            'min': float(np.min(ssim_scores)),\n",
    "            'max': float(np.max(ssim_scores))\n",
    "        },\n",
    "        'psnr': {\n",
    "            'mean': float(np.mean(psnr_scores)),\n",
    "            'std': float(np.std(psnr_scores)),\n",
    "            'min': float(np.min(psnr_scores)),\n",
    "            'max': float(np.max(psnr_scores))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics, ssim_scores, psnr_scores\n",
    "\n",
    "print(\"Metrics functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de04c4d",
   "metadata": {},
   "source": [
    "## 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384180d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs...\n",
      "Model: Fast-DDPM with 1000 diffusion steps\n",
      "Scheduler: uniform\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6928/18269 [21:03<24:13,  7.80it/s, loss=1]      "
     ]
    }
   ],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss_all': [],\n",
    "    'test_loss_dist2': [],\n",
    "    'test_loss_dist4': [],\n",
    "    'test_metrics_all': [],\n",
    "    'test_metrics_dist2': [],\n",
    "    'test_metrics_dist4': [],\n",
    "    'epoch_times': []\n",
    "}\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting training for {CONFIG['num_epochs']} epochs...\")\n",
    "print(f\"Model: Fast-DDPM with {CONFIG['num_timesteps']} diffusion steps\")\n",
    "print(f\"Scheduler: {CONFIG['scheduler_type']}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, diffusion_schedule, CONFIG['device'], CONFIG)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "    # Evaluate on distance 2 (3mm gap)\n",
    "    test_loss_dist2, pred_dist2, target_dist2 = evaluate(model, test_loader_dist2, criterion, diffusion_schedule, CONFIG['device'], CONFIG)\n",
    "    metrics_dist2, ssim_dist2, psnr_dist2 = compute_metrics_for_predictions(pred_dist2, target_dist2)\n",
    "    history['test_loss_dist2'].append(test_loss_dist2)\n",
    "    history['test_metrics_dist2'].append(metrics_dist2)\n",
    "    \n",
    "    print(f\"  Test Loss (Dist2-3mm): {test_loss_dist2:.6f}\")\n",
    "    print(f\"    SSIM: {metrics_dist2['ssim']['mean']:.4f} Â± {metrics_dist2['ssim']['std']:.4f}\")\n",
    "    print(f\"    PSNR: {metrics_dist2['psnr']['mean']:.4f} Â± {metrics_dist2['psnr']['std']:.4f}\")\n",
    "    \n",
    "    # Evaluate on distance 4 (6mm gap)\n",
    "    test_loss_dist4, pred_dist4, target_dist4 = evaluate(model, test_loader_dist4, criterion, diffusion_schedule, CONFIG['device'], CONFIG)\n",
    "    metrics_dist4, ssim_dist4, psnr_dist4 = compute_metrics_for_predictions(pred_dist4, target_dist4)\n",
    "    history['test_loss_dist4'].append(test_loss_dist4)\n",
    "    history['test_metrics_dist4'].append(metrics_dist4)\n",
    "    \n",
    "    print(f\"  Test Loss (Dist4-6mm): {test_loss_dist4:.6f}\")\n",
    "    print(f\"    SSIM: {metrics_dist4['ssim']['mean']:.4f} Â± {metrics_dist4['ssim']['std']:.4f}\")\n",
    "    print(f\"    PSNR: {metrics_dist4['psnr']['mean']:.4f} Â± {metrics_dist4['psnr']['std']:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling based on all test loss\n",
    "    scheduler.step(test_loss_all)\n",
    "    \n",
    "    # Early stopping and checkpointing\n",
    "    if test_loss_dist_2 < best_loss:\n",
    "        best_loss = test_loss_dist_2\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'config': CONFIG,\n",
    "            'best_loss': best_loss\n",
    "        }\n",
    "        ckpt_path = os.path.join(CONFIG['model_dir'], 'best_model.pth')\n",
    "        torch.save(checkpoint, ckpt_path)\n",
    "        print(f\"  âœ“ Saved best model (loss: {best_loss:.6f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG['early_stopping_patience']:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Regular checkpoint\n",
    "    if (epoch + 1) % CONFIG['ckpt_freq'] == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'config': CONFIG\n",
    "        }\n",
    "        ckpt_path = os.path.join(CONFIG['model_dir'], f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, ckpt_path)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    history['epoch_times'].append(epoch_time)\n",
    "    print(f\"  Time: {epoch_time:.2f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Training completed in {total_time/3600:.2f} hours\")\n",
    "print(f\"Best test loss: {best_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891f367",
   "metadata": {},
   "source": [
    "## 10. Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfe107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to JSON\n",
    "results_dict = {\n",
    "    'model_name': 'Fast-DDPM (v3)',\n",
    "    'dataset': 'Prostate-MRI-US-Biopsy',\n",
    "    'config': CONFIG,\n",
    "    'training_summary': {\n",
    "        'total_epochs_trained': len(history['train_loss']),\n",
    "        'total_training_time_hours': total_time / 3600,\n",
    "        'best_test_loss': best_loss,\n",
    "    },\n",
    "    'history': {\n",
    "        'train_loss': history['train_loss'],\n",
    "        'test_loss_all': history['test_loss_all'],\n",
    "        'test_loss_distance_2_3mm': history['test_loss_dist2'],\n",
    "        'test_loss_distance_4_6mm': history['test_loss_dist4'],\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'all_samples': {\n",
    "            'num_samples': len(pred_all),\n",
    "            'distance_2_3mm_gap': history['test_metrics_dist2'][-1] if history['test_metrics_dist2'] else None,\n",
    "            'distance_4_6mm_gap': history['test_metrics_dist4'][-1] if history['test_metrics_dist4'] else None,\n",
    "            'combined': history['test_metrics_all'][-1] if history['test_metrics_all'] else None,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(CONFIG['results_file'], 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "\n",
    "print(f\"Results saved to {CONFIG['results_file']}\")\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "print(\"\\nDistance 2 (3mm gap - (i, i+2) -> i+1):\")\n",
    "if history['test_metrics_dist2']:\n",
    "    m = history['test_metrics_dist2'][-1]\n",
    "    print(f\"  SSIM: {m['ssim']['mean']:.4f} Â± {m['ssim']['std']:.4f} [min: {m['ssim']['min']:.4f}, max: {m['ssim']['max']:.4f}]\")\n",
    "    print(f\"  PSNR: {m['psnr']['mean']:.4f} Â± {m['psnr']['std']:.4f} [min: {m['psnr']['min']:.4f}, max: {m['psnr']['max']:.4f}]\")\n",
    "\n",
    "print(\"\\nDistance 4 (6mm gap - (i, i+4) -> i+2):\")\n",
    "if history['test_metrics_dist4']:\n",
    "    m = history['test_metrics_dist4'][-1]\n",
    "    print(f\"  SSIM: {m['ssim']['mean']:.4f} Â± {m['ssim']['std']:.4f} [min: {m['ssim']['min']:.4f}, max: {m['ssim']['max']:.4f}]\")\n",
    "    print(f\"  PSNR: {m['psnr']['mean']:.4f} Â± {m['psnr']['std']:.4f} [min: {m['psnr']['min']:.4f}, max: {m['psnr']['max']:.4f}]\")\n",
    "\n",
    "print(\"\\nCombined (All samples):\")\n",
    "if history['test_metrics_all']:\n",
    "    m = history['test_metrics_all'][-1]\n",
    "    print(f\"  SSIM: {m['ssim']['mean']:.4f} Â± {m['ssim']['std']:.4f} [min: {m['ssim']['min']:.4f}, max: {m['ssim']['max']:.4f}]\")\n",
    "    print(f\"  PSNR: {m['psnr']['mean']:.4f} Â± {m['psnr']['std']:.4f} [min: {m['psnr']['min']:.4f}, max: {m['psnr']['max']:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6163c95",
   "metadata": {},
   "source": [
    "## 11. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax.plot(history['test_loss_all'], label='Test Loss (All)', marker='s')\n",
    "ax.plot(history['test_loss_dist2'], label='Test Loss (Distance 2 - 3mm)', marker='^')\n",
    "ax.plot(history['test_loss_dist4'], label='Test Loss (Distance 4 - 6mm)', marker='v')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_title('Training and Test Loss Over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM scores\n",
    "ax = axes[0, 1]\n",
    "ssim_all = [m['ssim']['mean'] for m in history['test_metrics_all']]\n",
    "ssim_dist2 = [m['ssim']['mean'] for m in history['test_metrics_dist2']]\n",
    "ssim_dist4 = [m['ssim']['mean'] for m in history['test_metrics_dist4']]\n",
    "ax.plot(ssim_all, label='SSIM (All)', marker='o')\n",
    "ax.plot(ssim_dist2, label='SSIM (Distance 2 - 3mm)', marker='s')\n",
    "ax.plot(ssim_dist4, label='SSIM (Distance 4 - 6mm)', marker='^')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('SSIM')\n",
    "ax.set_title('Structural Similarity Index (SSIM) Over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# PSNR scores\n",
    "ax = axes[1, 0]\n",
    "psnr_all = [m['psnr']['mean'] for m in history['test_metrics_all']]\n",
    "psnr_dist2 = [m['psnr']['mean'] for m in history['test_metrics_dist2']]\n",
    "psnr_dist4 = [m['psnr']['mean'] for m in history['test_metrics_dist4']]\n",
    "ax.plot(psnr_all, label='PSNR (All)', marker='o')\n",
    "ax.plot(psnr_dist2, label='PSNR (Distance 2 - 3mm)', marker='s')\n",
    "ax.plot(psnr_dist4, label='PSNR (Distance 4 - 6mm)', marker='^')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('PSNR (dB)')\n",
    "ax.set_title('Peak Signal-to-Noise Ratio (PSNR) Over Epochs')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Training time per epoch\n",
    "ax = axes[1, 1]\n",
    "ax.bar(range(len(history['epoch_times'])), history['epoch_times'], color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Training Time per Epoch')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['model_dir'], 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training history plot saved to {os.path.join(CONFIG['model_dir'], 'training_history.png')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45660e0",
   "metadata": {},
   "source": [
    "## 12. Metrics Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive metrics table\n",
    "metrics_data = []\n",
    "\n",
    "if history['test_metrics_dist2']:\n",
    "    m = history['test_metrics_dist2'][-1]\n",
    "    metrics_data.append({\n",
    "        'Model': 'Fast-DDPM',\n",
    "        'Gap Type': 'Distance 2 (3mm)',\n",
    "        'SSIM Mean': f\"{m['ssim']['mean']:.4f}\",\n",
    "        'SSIM Std': f\"{m['ssim']['std']:.4f}\",\n",
    "        'PSNR Mean': f\"{m['psnr']['mean']:.2f}\",\n",
    "        'PSNR Std': f\"{m['psnr']['std']:.2f}\",\n",
    "        'Num Samples': len(pred_dist2)\n",
    "    })\n",
    "\n",
    "if history['test_metrics_dist4']:\n",
    "    m = history['test_metrics_dist4'][-1]\n",
    "    metrics_data.append({\n",
    "        'Model': 'Fast-DDPM',\n",
    "        'Gap Type': 'Distance 4 (6mm)',\n",
    "        'SSIM Mean': f\"{m['ssim']['mean']:.4f}\",\n",
    "        'SSIM Std': f\"{m['ssim']['std']:.4f}\",\n",
    "        'PSNR Mean': f\"{m['psnr']['mean']:.2f}\",\n",
    "        'PSNR Std': f\"{m['psnr']['std']:.2f}\",\n",
    "        'Num Samples': len(pred_dist4)\n",
    "    })\n",
    "\n",
    "if history['test_metrics_all']:\n",
    "    m = history['test_metrics_all'][-1]\n",
    "    metrics_data.append({\n",
    "        'Model': 'Fast-DDPM',\n",
    "        'Gap Type': 'Combined',\n",
    "        'SSIM Mean': f\"{m['ssim']['mean']:.4f}\",\n",
    "        'SSIM Std': f\"{m['ssim']['std']:.4f}\",\n",
    "        'PSNR Mean': f\"{m['psnr']['mean']:.2f}\",\n",
    "        'PSNR Std': f\"{m['psnr']['std']:.2f}\",\n",
    "        'Num Samples': len(pred_all)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nFinal Metrics Comparison:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Save metrics table as CSV\n",
    "csv_path = os.path.join(CONFIG['model_dir'], 'metrics_summary.csv')\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nMetrics table saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f876e451",
   "metadata": {},
   "source": [
    "## 13. Model Inference (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform iterative denoising for inference\n",
    "def sample_with_schedule(model, x_input, diffusion_schedule, num_steps=10, scheduler_type='uniform'):\n",
    "    \"\"\"\n",
    "    Perform iterative denoising to generate samples\n",
    "    \n",
    "    Args:\n",
    "        model: Trained diffusion model\n",
    "        x_input: (B, 2, H, W) concatenated input and reference images\n",
    "        diffusion_schedule: DiffusionSchedule object\n",
    "        num_steps: Number of sampling steps\n",
    "        scheduler_type: 'uniform' or 'non-uniform'\n",
    "    Returns:\n",
    "        generated_samples: (B, 1, H, W) generated middle slices\n",
    "    \"\"\"\n",
    "    # Get sampling schedule\n",
    "    schedule = diffusion_schedule.get_sampler_schedule(num_steps, scheduler_type)\n",
    "    \n",
    "    # Initialize with noise\n",
    "    x_t = torch.randn(x_input.shape[0], 1, CONFIG['image_size'], CONFIG['image_size'], device=x_input.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Reverse diffusion process\n",
    "        for i in range(len(schedule) - 1):\n",
    "            t_curr = schedule[i]\n",
    "            t_next = schedule[i + 1] if i + 1 < len(schedule) else 0\n",
    "            \n",
    "            t = torch.full((x_t.shape[0],), t_curr, device=x_input.device, dtype=torch.long)\n",
    "            \n",
    "            # Predict noise\n",
    "            noise_pred = model(torch.cat([x_input, x_t], dim=1), t.float())\n",
    "            \n",
    "            # Compute denoising coefficients\n",
    "            alpha_t = diffusion_schedule.alphas_cumprod[t_curr]\n",
    "            alpha_next = diffusion_schedule.alphas_cumprod[t_next]\n",
    "            \n",
    "            # x_{t-1} prediction\n",
    "            x_t = (x_t - (1 - alpha_t).sqrt() * noise_pred) / alpha_t.sqrt()\n",
    "            \n",
    "            # Add noise for next step if not at the end\n",
    "            if t_next > 0:\n",
    "                sigma_t = ((1 - alpha_next) * (1 - alpha_t) / (1 - alpha_next)).sqrt()\n",
    "                x_t += sigma_t * torch.randn_like(x_t)\n",
    "    \n",
    "    return torch.clamp(x_t, -1, 1)\n",
    "\n",
    "print(\"Inference function defined. To perform inference on new samples:\")\n",
    "print(\"1. Load a batch: batch = next(iter(test_loader))\")\n",
    "print(\"2. Prepare input: x_input = torch.cat([batch['pre'], batch['post']], dim=1).to(device)\")\n",
    "print(\"3. Generate: samples = sample_with_schedule(model, x_input, diffusion_schedule, num_steps=10)\")\n",
    "print(\"\\nNote: For best results, load the best saved model checkpoint first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
