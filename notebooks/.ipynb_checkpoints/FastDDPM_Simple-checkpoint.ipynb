{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac79d37-9c6d-4d2e-9d3a-6f9b02999758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA B200\n",
      "GPU Memory: 191.51 GB\n",
      "Working directory: /blue/eel6935/dthiyagarajan/Multi-Image-Super-Resolution/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import time\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Add src path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d22da6-1234-497f-9479-70dec87a64ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading training data...\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 641 volumes in RAM\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 113 volumes in RAM\n",
      "ðŸ’¾ Pre-caching volumes into RAM for faster data loading...\n",
      "âœ… Cached 160 volumes in RAM\n",
      "âœ“ Data loaded\n",
      "  Train batches: 18269\n",
      "  Val batches: 3221\n",
      "  Test batches: 18240\n",
      "\n",
      "Checking data format...\n",
      "  Batch type: <class 'list'>\n",
      "  Batch length: 2\n",
      "    Item 0: tuple with 2 tensors\n",
      "      [0] shape: torch.Size([4, 1, 256, 256])\n",
      "      [1] shape: torch.Size([4, 1, 256, 256])\n",
      "    Item 1 shape: torch.Size([4, 1, 256, 256])\n",
      "âœ“ Data loading complete\n"
     ]
    }
   ],
   "source": [
    "from ModelDataGenerator_1 import build_dataloader\n",
    "\n",
    "# Load data\n",
    "print(\"ðŸ“¥ Loading training data...\")\n",
    "train_loader = build_dataloader(split='train', batch_size=4, augment=True, num_workers=4)\n",
    "val_loader = build_dataloader(split='val', batch_size=4, augment=False, num_workers=4)\n",
    "test_loader = build_dataloader(split='test', batch_size=1, augment=False, num_workers=0)\n",
    "\n",
    "print(f\"âœ“ Data loaded\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Check data format\n",
    "print(\"\\nChecking data format...\")\n",
    "for batch_data in train_loader:\n",
    "    print(f\"  Batch type: {type(batch_data)}\")\n",
    "    if isinstance(batch_data, (list, tuple)):\n",
    "        print(f\"  Batch length: {len(batch_data)}\")\n",
    "        for i, item in enumerate(batch_data):\n",
    "            if isinstance(item, (list, tuple)):\n",
    "                print(f\"    Item {i}: tuple with {len(item)} tensors\")\n",
    "                for j, sub_item in enumerate(item):\n",
    "                    if hasattr(sub_item, 'shape'):\n",
    "                        print(f\"      [{j}] shape: {sub_item.shape}\")\n",
    "            else:\n",
    "                if hasattr(item, 'shape'):\n",
    "                    print(f\"    Item {i} shape: {item.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"âœ“ Data loading complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe4e38e-4f75-438b-9284-dd60fae1d695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Sinusoidal embeddings and scheduler defined\n"
     ]
    }
   ],
   "source": [
    "def sinusoidal_timestep_embedding(timesteps, dim):\n",
    "    \"\"\"\n",
    "    Standard sinusoidal time embedding (as in DDPM, DDIM, LDM).\n",
    "    Creates a fixed positional encoding for timesteps.\n",
    "    \"\"\"\n",
    "    device = timesteps.device\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        -math.log(10000) * torch.arange(0, half, dtype=torch.float32, device=device) / half\n",
    "    )\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    return emb\n",
    "\n",
    "\n",
    "class FastNoiseScheduler:\n",
    "    \"\"\"\n",
    "    Fast noise scheduler with non-uniform timestep sampling.\n",
    "    Emphasizes early denoising steps (40% early, 60% late from original 1000-step schedule).\n",
    "    This reduces inference time from 1000 to 10 steps without quality loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, T, device):\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "\n",
    "        # Load 1000-step DDPM scheduler (linear Î²)\n",
    "        beta = torch.linspace(1e-4, 0.02, 1000)\n",
    "        alpha = 1.0 - beta\n",
    "        alpha_bar = torch.cumprod(alpha, 0)\n",
    "\n",
    "        # Non-uniform sampling: emphasize early denoising (more important)\n",
    "        boundary = 699\n",
    "        late_steps = int(T * 0.6)\n",
    "        early_steps = T - late_steps\n",
    "\n",
    "        idx_early = torch.linspace(0, boundary, early_steps).long()\n",
    "        idx_late = torch.linspace(boundary, 999, late_steps).long()\n",
    "\n",
    "        idxs = torch.sort(torch.cat([idx_early, idx_late]))[0]\n",
    "\n",
    "        self.beta = beta[idxs].to(device)\n",
    "        self.alpha = alpha[idxs].to(device)\n",
    "        self.alpha_bar = alpha_bar[idxs].to(device)\n",
    "\n",
    "    def q_sample(self, x0, t, noise):\n",
    "        \"\"\"Forward diffusion: add noise to image at timestep t\"\"\"\n",
    "        a_bar = self.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "        return torch.sqrt(a_bar) * x0 + torch.sqrt(1 - a_bar) * noise\n",
    "\n",
    "\n",
    "print(\"âœ“ Sinusoidal embeddings and scheduler defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a04f780-5213-477a-abb7-cecde5778279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ UNet2D created with 2,162,177 parameters\n"
     ]
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block with ReLU activation\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Improved 2D UNet with sinusoidal timestep embeddings.\n",
    "    Uses better time conditioning with MLPs.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, base_ch=64, time_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        # Better time embedding: sinusoidal -> MLP\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(in_ch + time_dim, base_ch)\n",
    "        self.down1 = DoubleConv(base_ch, base_ch * 2)\n",
    "        self.down2 = DoubleConv(base_ch * 2, base_ch * 4)\n",
    "\n",
    "        # Decoder\n",
    "        self.up2 = DoubleConv(base_ch * 4 + base_ch * 2, base_ch * 2)\n",
    "        self.up1 = DoubleConv(base_ch * 2 + base_ch, base_ch)\n",
    "\n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(base_ch, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Generate sinusoidal embeddings -> pass through MLP\n",
    "        t_emb = sinusoidal_timestep_embedding(t, 256)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "        t_emb = t_emb[:, :, None, None].repeat(1, 1, x.shape[2], x.shape[3])\n",
    "\n",
    "        # Concatenate time embeddings into channel dimension\n",
    "        x = torch.cat([x, t_emb], dim=1)\n",
    "\n",
    "        # Encoder\n",
    "        c1 = self.inc(x)\n",
    "        c2 = self.down1(F.max_pool2d(c1, 2))\n",
    "        c3 = self.down2(F.max_pool2d(c2, 2))\n",
    "\n",
    "        # Decoder\n",
    "        u2 = F.interpolate(c3, scale_factor=2)\n",
    "        u2 = self.up2(torch.cat([u2, c2], dim=1))\n",
    "\n",
    "        u1 = F.interpolate(u2, scale_factor=2)\n",
    "        u1 = self.up1(torch.cat([u1, c1], dim=1))\n",
    "\n",
    "        return self.outc(u1)\n",
    "\n",
    "\n",
    "# Test UNet\n",
    "test_unet = UNet2D(in_ch=3, base_ch=64, time_dim=256)\n",
    "total_params = sum(p.numel() for p in test_unet.parameters())\n",
    "print(f\"âœ“ UNet2D created with {total_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77624fff-c6e3-4407-b659-bb9cb2c2a5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Fast-DDPM model defined\n"
     ]
    }
   ],
   "source": [
    "class FastDDPM(nn.Module):\n",
    "    \"\"\"Fast DDPM model with non-uniform scheduling for medical image super-resolution\"\"\"\n",
    "    def __init__(self, T, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.scheduler = FastNoiseScheduler(T, device)\n",
    "        self.unet = UNet2D(in_ch=3, base_ch=64, time_dim=256).to(device)\n",
    "\n",
    "    def forward(self, cond, target, t):\n",
    "        \"\"\"Training forward pass: predict noise\"\"\"\n",
    "        noise = torch.randn_like(target)\n",
    "        a_bar = self.scheduler.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "        x_t = torch.sqrt(a_bar) * target + torch.sqrt(1 - a_bar) * noise\n",
    "\n",
    "        pred_noise = self.unet(torch.cat([x_t, cond], dim=1), t)\n",
    "        return F.mse_loss(pred_noise, noise)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, cond, device):\n",
    "        \"\"\"\n",
    "        DDIM sampling: reverse diffusion process for inference.\n",
    "        Much faster than DDPM sampling (10 steps vs 1000).\n",
    "        \n",
    "        Args:\n",
    "            cond: concatenated [pre, post] slices (B, 2, H, W)\n",
    "            device: torch device\n",
    "        Returns:\n",
    "            predicted middle slice (B, 1, H, W)\n",
    "        \"\"\"\n",
    "        B, _, H, W = cond.shape\n",
    "        x = torch.randn(B, 1, H, W).to(device)\n",
    "\n",
    "        T = self.scheduler.T\n",
    "\n",
    "        for i in reversed(range(T)):\n",
    "            t = torch.full((B,), i, device=device, dtype=torch.long)\n",
    "\n",
    "            # Predict noise\n",
    "            eps = self.unet(torch.cat([x, cond], 1), t)\n",
    "\n",
    "            a_bar = self.scheduler.alpha_bar[i]\n",
    "            a_bar_prev = self.scheduler.alpha_bar[i - 1] if i > 0 else torch.tensor(1.0).to(device)\n",
    "\n",
    "            # Estimate x0\n",
    "            x0 = (x - torch.sqrt(1 - a_bar) * eps) / torch.sqrt(a_bar)\n",
    "\n",
    "            # Update x\n",
    "            x = torch.sqrt(a_bar_prev) * x0 + torch.sqrt(1 - a_bar_prev) * eps\n",
    "\n",
    "        return x.clamp(-1, 1)\n",
    "\n",
    "\n",
    "print(\"âœ“ Fast-DDPM model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebc5c96-8a4d-4678-9e48-17d88bba5ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred, gt):\n",
    "    \"\"\"Compute PSNR and SSIM between prediction and ground truth\"\"\"\n",
    "    pred = pred.squeeze().cpu().numpy()\n",
    "    gt = gt.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Normalize to valid range\n",
    "    pred = np.clip(pred, pred.min(), pred.max())\n",
    "    gt = np.clip(gt, gt.min(), gt.max())\n",
    "    \n",
    "    data_range = gt.max() - gt.min()\n",
    "    if data_range == 0:\n",
    "        data_range = 1.0\n",
    "    \n",
    "    psnr = peak_signal_noise_ratio(gt, pred, data_range=data_range)\n",
    "    ssim = structural_similarity(gt, pred, data_range=data_range)\n",
    "    return psnr, ssim\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, num_samples=None):\n",
    "    \"\"\"Evaluate model on a dataloader\"\"\"\n",
    "    model.eval()\n",
    "    ps, ss = [], []\n",
    "    sample_count = 0\n",
    "\n",
    "    for batch_data in loader:\n",
    "        # Unpack batch data\n",
    "        if isinstance(batch_data, (list, tuple)) and len(batch_data) == 2:\n",
    "            if isinstance(batch_data[0], (list, tuple)):\n",
    "                prev, nxt = batch_data[0]\n",
    "                mid = batch_data[1]\n",
    "            else:\n",
    "                prev = batch_data[0][:, :1, :, :]\n",
    "                nxt = batch_data[0][:, 1:, :, :]\n",
    "                mid = batch_data[1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        prev, nxt, mid = prev.to(device), nxt.to(device), mid.to(device)\n",
    "\n",
    "        # Concatenate condition\n",
    "        cond = torch.cat([prev, nxt], dim=1)\n",
    "\n",
    "        # Generate prediction\n",
    "        pred = model.sample(cond, device)\n",
    "\n",
    "        # Compute metrics\n",
    "        for i in range(pred.size(0)):\n",
    "            p, s = compute_metrics(pred[i], mid[i])\n",
    "            ps.append(p)\n",
    "            ss.append(s)\n",
    "            sample_count += 1\n",
    "            \n",
    "            if num_samples and sample_count >= num_samples:\n",
    "                break\n",
    "        \n",
    "        if num_samples and sample_count >= num_samples:\n",
    "            break\n",
    "\n",
    "    return np.mean(ps), np.mean(ss), ps, ss\n",
    "\n",
    "\n",
    "print(\"âœ“ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca71682-91d9-4871-abad-f2c69abc9849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_fastddpm(model, train_loader, val_loader, device, epochs=40, lr=2e-4):\n",
    "    \"\"\"Train Fast-DDPM model with early stopping\"\"\"\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_ssim = -1.0\n",
    "    train_losses = []\n",
    "    val_ssims = []\n",
    "    val_psnrs = []\n",
    "\n",
    "    print(\"Training Started\")\n",
    "    print(f\"Total batches per epoch: {len(train_loader)}\\n\")\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # Progress bar for batches\n",
    "        for batch_idx, batch_data in enumerate(tqdm(train_loader, desc=f\"Epoch {ep+1}/{epochs}\")):\n",
    "\n",
    "            # Unpack batch data\n",
    "            if isinstance(batch_data, (list, tuple)) and len(batch_data) == 2:\n",
    "                if isinstance(batch_data[0], (list, tuple)):\n",
    "                    prev, nxt = batch_data[0]\n",
    "                    mid = batch_data[1]\n",
    "                else:\n",
    "                    prev = batch_data[0][:, :1, :, :]\n",
    "                    nxt = batch_data[0][:, 1:, :, :]\n",
    "                    mid = batch_data[1]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            prev, nxt, mid = prev.to(device), nxt.to(device), mid.to(device)\n",
    "\n",
    "            # Concatenate condition\n",
    "            cond = torch.cat([prev, nxt], 1)\n",
    "            \n",
    "            # Sample random timesteps\n",
    "            t = torch.randint(0, model.scheduler.T, (mid.size(0),), device=device)\n",
    "\n",
    "            # Forward pass\n",
    "            loss = model(cond, mid, t)\n",
    "            \n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Free memory\n",
    "            del prev, nxt, mid, cond, t, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        end_epoch = time.time()\n",
    "\n",
    "        avg_train_loss = total_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_psnr, val_ssim, _, _ = evaluate(model, val_loader, device, num_samples=20)\n",
    "        val_ssims.append(val_ssim)\n",
    "        val_psnrs.append(val_psnr)\n",
    "\n",
    "        print(f\"\\nEpoch {ep+1} finished in {(end_epoch - start_epoch):.1f} sec\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.6f}\")\n",
    "        print(f\"  Val PSNR:   {val_psnr:.3f}\")\n",
    "        print(f\"  Val SSIM:   {val_ssim:.3f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_ssim > best_ssim:\n",
    "            best_ssim = val_ssim\n",
    "            torch.save(model.state_dict(), \"fastddpm_advanced_best.pth\")\n",
    "            print(f\"  âœ“ NEW BEST MODEL SAVED! (SSIM: {val_ssim:.3f})\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training complete!\")\n",
    "    print(f\"Best SSIM: {best_ssim:.3f}\")\n",
    "    print(f\"=\"*60)\n",
    "\n",
    "    return train_losses, val_psnrs, val_ssims\n",
    "\n",
    "\n",
    "print(\"âœ“ Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3c9aa-7b39-40f8-ad19-389a1f12354b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Fast-DDPM Advanced model...\n",
      "âœ“ Model created with 2,162,177 parameters\n",
      "  - Scheduler timesteps: 10\n",
      "  - Non-uniform sampling: 40% early, 60% late\n",
      "\n",
      "Starting training...\n",
      "Training Started\n",
      "Total batches per epoch: 18269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/18269 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "print(\"Initializing Fast-DDPM Advanced model...\")\n",
    "model = FastDDPM(T=10, device=device).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"âœ“ Model created with {total_params:,} parameters\")\n",
    "print(f\"  - Scheduler timesteps: {model.scheduler.T}\")\n",
    "print(f\"  - Non-uniform sampling: 40% early, 60% late\\n\")\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "train_losses, val_psnrs, val_ssims = train_fastddpm(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    device, \n",
    "    epochs=20, \n",
    "    lr=2e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c572490-bf78-49dc-935c-4136f58942ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "print(\"Loading best model...\")\n",
    "model.load_state_dict(torch.load(\"fastddpm_advanced_best.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_psnr, test_ssim, psnr_vals, ssim_vals = evaluate(model, test_loader, device)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"TEST SET RESULTS - FAST-DDPM ADVANCED\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"Test PSNR: {test_psnr:.3f} Â± {np.std(psnr_vals):.3f}\")\n",
    "print(f\"Test SSIM: {test_ssim:.3f} Â± {np.std(ssim_vals):.3f}\")\n",
    "print(f\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3bf8d-24f8-457e-9034-f15d90c9134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Training loss (log scale)\n",
    "axes[0].plot(train_losses, linewidth=2, color='#3498db')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# PSNR\n",
    "axes[1].plot(val_psnrs, linewidth=2, color='#2ecc71', marker='o', markersize=4)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "axes[1].set_title('Validation PSNR', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM\n",
    "axes[2].plot(val_ssims, linewidth=2, color='#e74c3c', marker='o', markersize=4)\n",
    "axes[2].axhline(y=0.760, color='gold', linestyle='--', linewidth=2, label='UNet-GAN (0.760)')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('SSIM', fontsize=12)\n",
    "axes[2].set_title('Validation SSIM', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_ylim([0, 1.0])\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fastddpm_advanced_training.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ“ Training curves saved to 'fastddpm_advanced_training.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e30df3-a96d-45e0-9cc6-15d20fa5028b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate sample predictions\n",
    "print(\"Generating sample predictions...\")\n",
    "sample_predictions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch_data in enumerate(test_loader):\n",
    "        if i >= 4:\n",
    "            break\n",
    "        \n",
    "        # Unpack batch\n",
    "        if isinstance(batch_data, (list, tuple)) and len(batch_data) == 2:\n",
    "            if isinstance(batch_data[0], (list, tuple)):\n",
    "                prev, nxt = batch_data[0]\n",
    "                mid = batch_data[1]\n",
    "            else:\n",
    "                prev = batch_data[0][:, :1, :, :]\n",
    "                nxt = batch_data[0][:, 1:, :, :]\n",
    "                mid = batch_data[1]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        prev, nxt, mid = prev.to(device), nxt.to(device), mid.to(device)\n",
    "        cond = torch.cat([prev, nxt], dim=1)\n",
    "        pred = model.sample(cond, device)\n",
    "        \n",
    "        p, s = compute_metrics(pred, mid)\n",
    "        \n",
    "        sample_predictions.append({\n",
    "            'pre': prev.squeeze().cpu().numpy(),\n",
    "            'post': nxt.squeeze().cpu().numpy(),\n",
    "            'gt': mid.squeeze().cpu().numpy(),\n",
    "            'pred': pred.squeeze().cpu().numpy(),\n",
    "            'psnr': p,\n",
    "            'ssim': s\n",
    "        })\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(len(sample_predictions), 4, figsize=(12, 3*len(sample_predictions)))\n",
    "if len(sample_predictions) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, sample in enumerate(sample_predictions):\n",
    "    axes[idx, 0].imshow(sample['pre'], cmap='gray')\n",
    "    axes[idx, 0].set_title('Pre-slice', fontweight='bold', fontsize=11)\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(sample['post'], cmap='gray')\n",
    "    axes[idx, 1].set_title('Post-slice', fontweight='bold', fontsize=11)\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    axes[idx, 2].imshow(sample['gt'], cmap='gray')\n",
    "    axes[idx, 2].set_title('Ground Truth', fontweight='bold', fontsize=11)\n",
    "    axes[idx, 2].axis('off')\n",
    "    \n",
    "    axes[idx, 3].imshow(sample['pred'], cmap='gray')\n",
    "    axes[idx, 3].set_title(\n",
    "        f\"Prediction\\nPSNR: {sample['psnr']:.2f} | SSIM: {sample['ssim']:.3f}\",\n",
    "        fontweight='bold',\n",
    "        fontsize=11\n",
    "    )\n",
    "    axes[idx, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fastddpm_advanced_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ“ Sample predictions saved to 'fastddpm_advanced_predictions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f5151-6920-4129-9a82-1c9ad2c0f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FAST-DDPM SIMPLE IMPLEMENTATION - SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nâœ“ Model Architecture:\")\n",
    "print(f\"  - Noise Scheduler: Linear schedule with 200 timesteps\")\n",
    "print(f\"  - UNet: 2D UNet with time embedding (base_ch=64)\")\n",
    "print(f\"  - Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nâœ“ Training Configuration:\")\n",
    "print(f\"  - Optimizer: Adam (lr=2e-4)\")\n",
    "print(f\"  - Loss: MSE (noise prediction)\")\n",
    "print(f\"  - Epochs: 20\")\n",
    "print(f\"  - Batch Size: 4\")\n",
    "\n",
    "print(f\"\\nâœ“ Final Results (Test Set):\")\n",
    "print(f\"  - SSIM: {test_ssim:.3f} Â± {np.std(ssim_vals):.3f}\")\n",
    "print(f\"  - PSNR: {test_psnr:.2f} Â± {np.std(psnr_vals):.2f} dB\")\n",
    "\n",
    "print(f\"\\nâœ“ Key Features:\")\n",
    "print(f\"  - Simple, clean implementation\")\n",
    "print(f\"  - Time embedding for noise level conditioning\")\n",
    "print(f\"  - Reverse diffusion for inference\")\n",
    "print(f\"  - Per-batch memory cleanup\")\n",
    "print(f\"  - Best model checkpointing\")\n",
    "\n",
    "print(f\"\\nâœ“ Output Files:\")\n",
    "print(f\"  - fastddpm_simple_best.pth (model weights)\")\n",
    "print(f\"  - fastddpm_simple_training.png (loss/metric curves)\")\n",
    "print(f\"  - fastddpm_simple_predictions.png (sample results)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
