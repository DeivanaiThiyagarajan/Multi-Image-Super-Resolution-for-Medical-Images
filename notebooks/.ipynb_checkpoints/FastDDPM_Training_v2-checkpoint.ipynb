{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324b8306",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae4b2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA B200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccef1a4",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192bcff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: Train=18269, Val=3221, Test=4560\n",
      "\n",
      "Batch shapes:\n",
      "  pre: torch.Size([4, 1, 256, 256])\n",
      "  post: torch.Size([4, 1, 256, 256])\n",
      "  target: torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Add src to path and import data generator\n",
    "sys.path.insert(0, '../src')\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "CHECKPOINT_DIR = '../models'\n",
    "results_dir = '../results'\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = build_dataloader(split='train', batch_size=BATCH_SIZE, augment=True, num_workers=NUM_WORKERS)\n",
    "val_loader = build_dataloader(split='val', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "test_loader = build_dataloader(split='test', batch_size=BATCH_SIZE, augment=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"‚úÖ Data loaded: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")\n",
    "\n",
    "# Check one batch\n",
    "(pre_sample, post_sample), target_sample = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  pre: {pre_sample.shape}\")\n",
    "print(f\"  post: {post_sample.shape}\")\n",
    "print(f\"  target: {target_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4a0fe",
   "metadata": {},
   "source": [
    "## 3. Noise Schedule (DDPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f08b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scheduler created with type: 'non-uniform'\n",
      "‚úÖ Inference steps: [0, 199, 399, 599, 699, 799, 849, 899, 949, 999]\n"
     ]
    }
   ],
   "source": [
    "class DDPMScheduler:\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform'):\n",
    "        \n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.scheduler_type = scheduler_type\n",
    "        \n",
    "        # Pre-compute noise schedule (same as standard DDPM)\n",
    "        betas = torch.linspace(0.0001, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1 - alphas_cumprod))\n",
    "        \n",
    "        # Select timesteps based on strategy\n",
    "        if scheduler_type == 'uniform':\n",
    "            # Uniform spacing: every skip-th timestep\n",
    "            skip = num_timesteps // num_inference_steps\n",
    "            self.timesteps = torch.arange(0, num_timesteps, skip).long()[:num_inference_steps]\n",
    "        \n",
    "        elif scheduler_type == 'non-uniform':\n",
    "            # Non-uniform: concentrate in noisy region\n",
    "            if num_inference_steps == 10:\n",
    "                # Exact from paper: [0, 199, 399, 599, 699, 799, 849, 899, 949, 999]\n",
    "                self.timesteps = torch.tensor([0, 199, 399, 599, 699, 799, 849, 899, 949, 999]).long()\n",
    "            else:\n",
    "                # Adaptive non-uniform for other step counts\n",
    "                # 40% in early stage (0-699), 60% in late stage (699-999)\n",
    "                num_stage1 = int(num_inference_steps * 0.4)\n",
    "                num_stage2 = int(num_inference_steps * 0.6)\n",
    "                \n",
    "                if num_stage1 > 0:\n",
    "                    stage1 = torch.linspace(0, 699, num_stage1 + 1)[:-1].ceil().long()\n",
    "                else:\n",
    "                    stage1 = torch.tensor([]).long()\n",
    "                \n",
    "                stage2 = torch.linspace(699, 999, num_stage2 + 1)[:-1].ceil().long()\n",
    "                self.timesteps = torch.cat([stage1, stage2])\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler_type: {scheduler_type}\")\n",
    "    \n",
    "    def register_buffer(self, name, tensor):\n",
    "        setattr(self, name, tensor)\n",
    "    \n",
    "    def add_noise(self, x0, t, noise):\n",
    "        \"\"\"Forward process: x_t = sqrt(alpha_t)*x0 + sqrt(1-alpha_t)*eps\"\"\"\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "\n",
    "# Create scheduler (change to 'uniform' if preferred)\n",
    "scheduler = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "print(f\"‚úÖ Scheduler created with type: 'non-uniform'\")\n",
    "print(f\"‚úÖ Inference steps: {scheduler.timesteps.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f4b57",
   "metadata": {},
   "source": [
    "## 4. Model Architecture (with 3 input channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814a5bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model created with 3 input channels: 13,899,905 parameters\n"
     ]
    }
   ],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    Build sinusoidal embeddings (from DDPM paper).\n",
    "    This matches the implementation in Fairseq.\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "    \n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal timestep embedding with learned projection\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        # Project sinusoidal embedding to desired dimension\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim * 2, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t):\n",
    "        # t: (batch,) or scalar\n",
    "        if t.dim() == 0:\n",
    "            t = t.unsqueeze(0)\n",
    "        # Get sinusoidal embedding\n",
    "        emb = get_timestep_embedding(t, self.dim)  # (batch, dim)\n",
    "        # Project through FC layers\n",
    "        return self.fc(emb)  # (batch, dim)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Residual block with time conditioning\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, time_dim):\n",
    "        super().__init__()\n",
    "        # Adaptive GroupNorm: num_groups = channels // 4\n",
    "        ng_in = max(1, in_ch // 4)\n",
    "        ng_out = max(1, out_ch // 4)\n",
    "        \n",
    "        self.norm1 = nn.GroupNorm(ng_in, in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(ng_out, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        \n",
    "        # Time conditioning\n",
    "        self.time_fc = nn.Linear(time_dim, out_ch)\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = F.silu(self.norm1(x))\n",
    "        h = self.conv1(h)\n",
    "        h = h + self.time_fc(t_emb)[:, :, None, None]  # Add time conditioning\n",
    "        h = F.silu(self.norm2(h))\n",
    "        h = self.conv2(h)\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class FastDDPM(nn.Module):\n",
    "    \"\"\"Fast DDPM UNet for conditional denoising\"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=1, base_ch=64, time_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_dim)\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ResBlock(base_ch, base_ch * 2, time_dim)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ResBlock(base_ch * 2, base_ch * 4, time_dim)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ResBlock(base_ch * 4, base_ch * 8, time_dim)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlock(base_ch * 8, base_ch * 8, time_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, 2)\n",
    "        self.dec3 = ResBlock(base_ch * 4 + base_ch * 8, base_ch * 4, time_dim)  # in_ch = concatenated channels\n",
    "    \n",
    "        self.upconv2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, 2)\n",
    "        self.dec2 = ResBlock(base_ch * 2 + base_ch * 4, base_ch * 2, time_dim)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, 2)\n",
    "        self.dec1 = ResBlock(base_ch + base_ch * 2, base_ch, time_dim)\n",
    "        \n",
    "        # Final output\n",
    "        ng_final = max(1, base_ch // 4)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.GroupNorm(ng_final, base_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, out_ch, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_emb(t)\n",
    "        \n",
    "        # Initial conv\n",
    "        h = self.init_conv(x)\n",
    "        \n",
    "        # Encoder with skip connections\n",
    "        e1 = self.enc1(h, t_emb)\n",
    "        h = self.pool1(e1)\n",
    "        e2 = self.enc2(h, t_emb)\n",
    "        h = self.pool2(e2)\n",
    "        e3 = self.enc3(h, t_emb)\n",
    "        h = self.pool3(e3)\n",
    "        \n",
    "        # Bottleneck\n",
    "        h = self.bottleneck(h, t_emb)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        h = self.upconv3(h)\n",
    "        h = torch.cat([h, e3], dim=1)\n",
    "        h = self.dec3(h, t_emb)\n",
    "        \n",
    "        h = self.upconv2(h)\n",
    "        h = torch.cat([h, e2], dim=1)\n",
    "        h = self.dec2(h, t_emb)\n",
    "        \n",
    "        h = self.upconv1(h)\n",
    "        h = torch.cat([h, e1], dim=1)\n",
    "        h = self.dec1(h, t_emb)\n",
    "        \n",
    "        return self.final(h)\n",
    "\n",
    "# Create model with 3 input channels: [pre, post, noisy_target]\n",
    "model = FastDDPM(in_ch=3, out_ch=1, base_ch=64, time_dim=128).to(DEVICE)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ Model created with 3 input channels: {num_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c79af8",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd056d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Checkpoint utilities defined\n",
      "\n",
      "üîç Checking for existing checkpoints...\n",
      "üì≠ No checkpoint found - starting fresh training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Checkpoint Utilities ==========\n",
    "def get_latest_checkpoint(checkpoint_dir, prefix='fastddpm_checkpoint'):\n",
    "    \"\"\"Get the latest checkpoint file by epoch number\"\"\"\n",
    "    from pathlib import Path\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    checkpoint_files = list(checkpoint_dir.glob(f'{prefix}_*.pt'))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    \n",
    "    # Extract epoch numbers and sort\n",
    "    checkpoints_with_epochs = []\n",
    "    for ckpt in checkpoint_files:\n",
    "        try:\n",
    "            epoch = int(ckpt.stem.split('_')[-1])\n",
    "            checkpoints_with_epochs.append((epoch, ckpt))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    if not checkpoints_with_epochs:\n",
    "        return None\n",
    "    \n",
    "    # Return path of checkpoint with highest epoch\n",
    "    latest_epoch, latest_ckpt = max(checkpoints_with_epochs, key=lambda x: x[0])\n",
    "    return latest_ckpt, latest_epoch\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, checkpoint_path, device):\n",
    "    \"\"\"Load checkpoint and return starting epoch and training state\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    history = checkpoint.get('history', {'epoch': [], 'train_loss': [], 'val_loss': []})\n",
    "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "    \n",
    "    return start_epoch, history, best_loss, checkpoint\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path):\n",
    "    \"\"\"Save checkpoint\"\"\"\n",
    "    from datetime import datetime\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "        'best_loss': best_loss,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(\"‚úÖ Checkpoint utilities defined\")\n",
    "\n",
    "# ========== Setup training with checkpoint support ==========\n",
    "# Check for existing checkpoint\n",
    "print(\"\\nüîç Checking for existing checkpoints...\")\n",
    "latest_ckpt_info = get_latest_checkpoint(CHECKPOINT_DIR, prefix='fastddpm_checkpoint')\n",
    "\n",
    "if latest_ckpt_info is not None:\n",
    "    latest_ckpt_path, latest_epoch = latest_ckpt_info\n",
    "    print(f\"üìÇ Found checkpoint: {latest_ckpt_path.name}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    start_epoch, history, best_loss, loaded_ckpt = load_checkpoint(\n",
    "        model, optimizer, scheduler_device, latest_ckpt_path, DEVICE\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Loaded checkpoint from epoch {latest_epoch}\")\n",
    "    print(f\"   Resuming training from epoch {start_epoch}\")\n",
    "    print(f\"   Best validation loss so far: {best_loss:.4f}\")\n",
    "    print(f\"   Epochs completed: {latest_epoch}\\n\")\n",
    "else:\n",
    "    print(\"üì≠ No checkpoint found - starting fresh training\\n\")\n",
    "    start_epoch = 1\n",
    "    history = {'epoch': [], 'train_loss': [], 'val_loss': []}\n",
    "    best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04323f16-8093-40d7-ad95-f8aa7d3c8e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler_device = DDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "scheduler_device.betas = scheduler_device.betas.to(DEVICE)\n",
    "scheduler_device.alphas_cumprod = scheduler_device.alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.sqrt_alphas_cumprod = scheduler_device.sqrt_alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.sqrt_one_minus_alphas_cumprod = scheduler_device.sqrt_one_minus_alphas_cumprod.to(DEVICE)\n",
    "scheduler_device.timesteps = scheduler_device.timesteps.to(DEVICE)\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (pre, post), target in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        # Move to device\n",
    "        pre = pre.to(DEVICE)\n",
    "        post = post.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        # Antithetic sampling: pair timesteps for better coverage (from paper)\n",
    "        batch_size = pre.shape[0]\n",
    "        t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size // 2 + 1,), device=DEVICE)\n",
    "        t_idx = torch.cat([t_idx, len(scheduler_device.timesteps) - t_idx - 1], dim=0)[:batch_size]\n",
    "        t = scheduler_device.timesteps[t_idx]  # (B,) on DEVICE\n",
    "        \n",
    "        # Forward process: add noise to target\n",
    "        noise = torch.randn_like(target).to(DEVICE)\n",
    "        x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "        \n",
    "        # Concatenate: [pre_slice, post_slice, noisy_target_slice]\n",
    "        x_input = torch.cat([pre, post, x_noisy], dim=1)  # (B, 3, H, W)\n",
    "        \n",
    "        # Model prediction: predict the noise\n",
    "        pred_noise = model(x_input, t)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(pred_noise, noise)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Clear cache to free memory\n",
    "        del pre, post, target, noise, x_noisy, x_input, pred_noise, loss, t, t_idx\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (pre, post), target in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "            pre = pre.to(DEVICE)\n",
    "            post = post.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "            \n",
    "            batch_size = pre.shape[0]\n",
    "            t_idx = torch.randint(0, len(scheduler_device.timesteps), (batch_size,), device=DEVICE)\n",
    "            t = scheduler_device.timesteps[t_idx]\n",
    "            \n",
    "            noise = torch.randn_like(target).to(DEVICE)\n",
    "            x_noisy = scheduler_device.add_noise(target, t, noise)\n",
    "            \n",
    "            x_input = torch.cat([pre, post, x_noisy], dim=1)  # (B, 3, H, W)\n",
    "            \n",
    "            pred_noise = model(x_input, t)\n",
    "            loss = criterion(pred_noise, noise)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Clear cache to free memory\n",
    "            del pre, post, target, noise, x_noisy, x_input, pred_noise, loss, t, t_idx\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a34e6",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda7383-97b0-4900-acd3-c760e10cde0f",
   "metadata": {},
   "source": [
    "## Epoch 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e7d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Starting Training Loop\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20 | Train: 0.0870 | Val: 0.1029 ‚úÖ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/20 | Train: 0.0860 | Val: 0.0997 ‚úÖ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/20 | Train: 0.0841 | Val: 0.0976 ‚úÖ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/20 | Train: 0.0857 | Val: 0.0966 ‚úÖ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 8345/18269 [48:21<1:09:41,  2.37it/s]"
     ]
    }
   ],
   "source": [
    "# ========== Training Loop with Checkpoint Support ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Starting Training Loop\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    # Update best loss and save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" ‚úÖ (best)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Save checkpoint after every epoch\n",
    "    checkpoint_path = f'{CHECKPOINT_DIR}/fastddpm_checkpoint_{epoch}.pt'\n",
    "    save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path)\n",
    "\n",
    "# Save final history\n",
    "with open(f'{results_dir}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete! Best val loss: {best_loss:.4f}\")\n",
    "print(f\"üìä Final history saved to fastddpm_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae75d6d-f48b-47bc-9ded-2a9af18c0359",
   "metadata": {},
   "source": [
    "## Epoch 5 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd20ba-00f2-44bf-aa6f-f763bc19eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Training Loop with Checkpoint Support ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Starting Training Loop\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    train_loss = train_epoch()\n",
    "    val_loss = validate()\n",
    "    \n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\", end=\"\")\n",
    "    \n",
    "    # Update best loss and save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/fastddpm_best.pt')\n",
    "        print(\" ‚úÖ (best)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Save checkpoint after every epoch\n",
    "    checkpoint_path = f'{CHECKPOINT_DIR}/fastddpm_checkpoint_{epoch}.pt'\n",
    "    save_checkpoint(model, optimizer, epoch, history, best_loss, checkpoint_path)\n",
    "\n",
    "# Save final history\n",
    "with open(f'{results_dir}/fastddpm_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete! Best val loss: {best_loss:.4f}\")\n",
    "print(f\"üìä Final history saved to fastddpm_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883f433",
   "metadata": {},
   "source": [
    "## 7. Sampling (Reverse Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(pre, post, num_samples=1):\n",
    "    \"\"\"Generate samples using reverse diffusion\"\"\"\n",
    "    model.eval()\n",
    "    batch_size = pre.shape[0]\n",
    "    \n",
    "    generated = []\n",
    "    for _ in range(num_samples):\n",
    "        # Start with random noise for the target\n",
    "        x_t = torch.randn(batch_size, 1, 256, 256, device=DEVICE, dtype=torch.float32)\n",
    "        \n",
    "        # Reverse process (denoising)\n",
    "        for step_idx, t_idx in enumerate(reversed(range(len(scheduler_device.timesteps)))):\n",
    "            t = scheduler_device.timesteps[t_idx]\n",
    "            t_batch = t.unsqueeze(0).expand(batch_size)\n",
    "            \n",
    "            # Concatenate: [clean_pre, clean_post, current_noisy_target]\n",
    "            x_input = torch.cat([pre.to(DEVICE), post.to(DEVICE), x_t], dim=1)  # (B, 3, H, W)\n",
    "            \n",
    "            # Predict noise at this timestep\n",
    "            pred_noise = model(x_input, t_batch)\n",
    "            \n",
    "            # Reverse step - ensure all tensors on DEVICE\n",
    "            alpha_t = scheduler_device.alphas_cumprod[t]\n",
    "            if t_idx > 0:\n",
    "                t_prev_idx = scheduler_device.timesteps[t_idx - 1]\n",
    "                alpha_prev = scheduler_device.alphas_cumprod[t_prev_idx]\n",
    "            else:\n",
    "                alpha_prev = torch.tensor(1.0, device=DEVICE, dtype=torch.float32)\n",
    "            \n",
    "            # Posterior variance\n",
    "            posterior_var = (1 - alpha_prev) / (1 - alpha_t) * (1 - alpha_t / alpha_prev)\n",
    "            posterior_var = torch.clamp(posterior_var, min=1e-20)\n",
    "            \n",
    "            noise = torch.randn_like(x_t, device=DEVICE) if t_idx > 0 else torch.zeros_like(x_t)\n",
    "            \n",
    "            # Denoising step\n",
    "            x_t = (1.0 / torch.sqrt(alpha_t)) * (x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_t) * pred_noise) + torch.sqrt(posterior_var) * noise\n",
    "        \n",
    "        generated.append(x_t.cpu())\n",
    "    \n",
    "    return torch.stack(generated, dim=1)\n",
    "\n",
    "print(\"‚úÖ Sampling function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9af89",
   "metadata": {},
   "source": [
    "## 8. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['epoch'], history['train_loss'], 'o-', label='Train Loss', linewidth=2)\n",
    "plt.plot(history['epoch'], history['val_loss'], 's-', label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Fast-DDPM Training History', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/fastddpm_training.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Plot saved to {results_dir}/fastddpm_training.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f8946",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b97910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/fastddpm_best.pt'))\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "predictions = []\n",
    "targets_list = []\n",
    "\n",
    "for (pre, post), target in tqdm(test_loader, desc=\"Testing\"):\n",
    "    generated = sample(pre, post, num_samples=3)\n",
    "    predictions.append(generated.cpu())\n",
    "    targets_list.append(target.cpu())\n",
    "    pred = generated.mean(dim=1).squeeze().numpy()\n",
    "    gt = target.squeeze().numpy()\n",
    "    \n",
    "    for i in range(len(gt)):\n",
    "        gt_norm = (gt[i] - gt[i].min()) / (gt[i].max() - gt[i].min() + 1e-8)\n",
    "        pred_norm = (pred[i] - pred[i].min()) / (pred[i].max() - pred[i].min() + 1e-8)\n",
    "        \n",
    "        ssim_scores.append(ssim(gt_norm, pred_norm, data_range=1.0))\n",
    "        psnr_scores.append(psnr(gt_norm, pred_norm, data_range=1.0))\n",
    "        \n",
    "        \n",
    "    # Clear GPU cache\n",
    "    del generated, pred, gt, gt_norm, pred_norm\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"SSIM: {np.mean(ssim_scores):.4f} ¬± {np.std(ssim_scores):.4f}\")\n",
    "print(f\"PSNR: {np.mean(psnr_scores):.2f} ¬± {np.std(psnr_scores):.2f} dB\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46ff54-7455-4d4f-a345-4f67c9e1d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all predictions and targets\n",
    "all_predictions = torch.cat(predictions, dim=0)  # (N, 1, H, W)\n",
    "all_targets = torch.cat(targets_list, dim=0)      # (N, 1, H, W)\n",
    "\n",
    "# Visualize some predictions\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(12, 4*n_samples))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    pred = all_predictions[i, 0].numpy()\n",
    "    target = all_targets[i, 0].numpy()\n",
    "    diff = np.abs(pred - target)\n",
    "    \n",
    "    axes[i, 0].imshow(target, cmap='gray')\n",
    "    axes[i, 0].set_title(f'Target Slice {i+1}', fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(pred, cmap='gray')\n",
    "    axes[i, 1].set_title(f'FastDDPM-Generated Slice {i+1}', fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    im = axes[i, 2].imshow(diff, cmap='hot')\n",
    "    axes[i, 2].set_title(f'Difference {i+1}', fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "pred_path = RESULTS_SAVE_DIR / 'fast_ddpm_predictions.png'\n",
    "plt.savefig(pred_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Predictions saved to {pred_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia-2",
   "language": "python",
   "name": "dlmia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
