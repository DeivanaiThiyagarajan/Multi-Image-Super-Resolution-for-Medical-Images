{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68d561a",
   "metadata": {},
   "source": [
    "# Fast-DDPM: Improved Implementation for Medical Image Super-Resolution\n",
    "\n",
    "This notebook implements the **Fast Denoising Diffusion Probabilistic Model (Fast-DDPM)** from https://github.com/mirthAI/Fast-DDPM for improved SSIM and PSNR scores on middle-slice prediction.\n",
    "\n",
    "## Key Improvements Over Basic DDPM\n",
    "1. **Accelerated Sampling**: Use only 10 timesteps instead of 1000 (100x faster inference)\n",
    "2. **Smarter Scheduling**: Non-uniform timestep selection emphasizing important denoising stages\n",
    "3. **Attention Blocks**: Self-attention at different resolutions for better feature learning\n",
    "4. **Time Embeddings**: Sinusoidal positional embeddings for timestep conditioning\n",
    "5. **Antithetic Sampling**: Better variance reduction during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Check GPU availability\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Add src path for imports\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath('.'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3454f96",
   "metadata": {},
   "source": [
    "## Core Components: DDPM Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a68166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    Build sinusoidal embeddings for timesteps.\n",
    "    This follows the implementation in Denoising Diffusion Probabilistic Models.\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1, 0, 0))\n",
    "    return emb\n",
    "\n",
    "def nonlinearity(x):\n",
    "    return F.silu(x)\n",
    "\n",
    "def Normalize(in_channels):\n",
    "    return nn.GroupNorm(num_groups=min(32, in_channels // 4), num_channels=in_channels, eps=1e-6)\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if with_conv:\n",
    "            self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
    "        if self.with_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, with_conv):\n",
    "        super().__init__()\n",
    "        self.with_conv = with_conv\n",
    "        if with_conv:\n",
    "            self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.with_conv:\n",
    "            pad = (0, 1, 0, 1)\n",
    "            x = F.pad(x, pad, mode='constant', value=0)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False, dropout, temb_channels=512):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        out_channels = in_channels if out_channels is None else out_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_conv_shortcut = conv_shortcut\n",
    "\n",
    "        self.norm1 = Normalize(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.temb_proj = nn.Linear(temb_channels, out_channels)\n",
    "        self.norm2 = Normalize(out_channels)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            if conv_shortcut:\n",
    "                self.conv_shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            else:\n",
    "                self.nin_shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, x, temb):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv1(h)\n",
    "        h = h + self.temb_proj(nonlinearity(temb))[:, :, None, None]\n",
    "        h = self.norm2(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.dropout_layer(h)\n",
    "        h = self.conv2(h)\n",
    "        \n",
    "        if self.in_channels != self.out_channels:\n",
    "            if self.use_conv_shortcut:\n",
    "                x = self.conv_shortcut(x)\n",
    "            else:\n",
    "                x = self.nin_shortcut(x)\n",
    "        \n",
    "        return x + h\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.norm = Normalize(in_channels)\n",
    "        self.q = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.k = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.v = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.proj_out = nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_ = x\n",
    "        h_ = self.norm(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        \n",
    "        # Compute attention\n",
    "        b, c, h, w = q.shape\n",
    "        q = q.reshape(b, c, h*w)\n",
    "        q = q.permute(0, 2, 1)  # (b, hw, c)\n",
    "        k = k.reshape(b, c, h*w)  # (b, c, hw)\n",
    "        w_ = torch.bmm(q, k)  # (b, hw, hw)\n",
    "        w_ = w_ * (int(c)**(-0.5))\n",
    "        w_ = F.softmax(w_, dim=2)\n",
    "        \n",
    "        # Attend to values\n",
    "        v = v.reshape(b, c, h*w)\n",
    "        h_ = torch.bmm(v, w_.permute(0, 2, 1))\n",
    "        h_ = h_.reshape(b, c, h, w)\n",
    "        h_ = self.proj_out(h_)\n",
    "        \n",
    "        return x + h_\n",
    "\n",
    "print(\"âœ“ Core components loaded (Attention blocks, ResNet blocks, embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a62f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDDPM(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet architecture for DDPM with attention blocks.\n",
    "    Input: (batch, 2, H, W) - two consecutive slices\n",
    "    Output: (batch, 1, H, W) - noise prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=2, out_channels=1, ch=64, ch_mult=(1,2,4,8), \n",
    "                 num_res_blocks=2, attn_resolutions=(16,), dropout=0.1, resolution=256):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ch = ch\n",
    "        self.ch_mult = ch_mult\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attn_resolutions = attn_resolutions\n",
    "        self.resolution = resolution\n",
    "        self.num_resolutions = len(ch_mult)\n",
    "        \n",
    "        # Timestep embedding\n",
    "        self.temb_ch = ch * 4\n",
    "        self.temb = nn.ModuleList([\n",
    "            nn.Linear(ch, self.temb_ch),\n",
    "            nn.Linear(self.temb_ch, self.temb_ch),\n",
    "        ])\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv_in = nn.Conv2d(in_channels, ch, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down = nn.ModuleList()\n",
    "        curr_res = resolution\n",
    "        in_ch_mult = (1,) + ch_mult\n",
    "        \n",
    "        for i_level in range(self.num_resolutions):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_in = ch * in_ch_mult[i_level]\n",
    "            block_out = ch * ch_mult[i_level]\n",
    "            \n",
    "            for i_block in range(num_res_blocks):\n",
    "                block.append(ResnetBlock(\n",
    "                    in_channels=block_in, out_channels=block_out,\n",
    "                    temb_channels=self.temb_ch, dropout=dropout\n",
    "                ))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(AttnBlock(block_in))\n",
    "            \n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.attn = attn\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                down.downsample = Downsample(block_in, with_conv=True)\n",
    "                curr_res = curr_res // 2\n",
    "            self.down.append(down)\n",
    "        \n",
    "        # Middle\n",
    "        self.mid = nn.Module()\n",
    "        self.mid.block_1 = ResnetBlock(in_channels=block_in, out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch, dropout=dropout)\n",
    "        self.mid.attn_1 = AttnBlock(block_in)\n",
    "        self.mid.block_2 = ResnetBlock(in_channels=block_in, out_channels=block_in,\n",
    "                                       temb_channels=self.temb_ch, dropout=dropout)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up = nn.ModuleList()\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            block = nn.ModuleList()\n",
    "            attn = nn.ModuleList()\n",
    "            block_out = ch * ch_mult[i_level]\n",
    "            skip_in = ch * ch_mult[i_level]\n",
    "            \n",
    "            for i_block in range(num_res_blocks + 1):\n",
    "                if i_block == num_res_blocks:\n",
    "                    skip_in = ch * in_ch_mult[i_level]\n",
    "                block.append(ResnetBlock(\n",
    "                    in_channels=block_in + skip_in, out_channels=block_out,\n",
    "                    temb_channels=self.temb_ch, dropout=dropout\n",
    "                ))\n",
    "                block_in = block_out\n",
    "                if curr_res in attn_resolutions:\n",
    "                    attn.append(AttnBlock(block_in))\n",
    "            \n",
    "            up = nn.Module()\n",
    "            up.block = block\n",
    "            up.attn = attn\n",
    "            if i_level != 0:\n",
    "                up.upsample = Upsample(block_in, with_conv=True)\n",
    "                curr_res = curr_res * 2\n",
    "            self.up.insert(0, up)\n",
    "        \n",
    "        # Final output\n",
    "        self.norm_out = Normalize(block_in)\n",
    "        self.conv_out = nn.Conv2d(block_in, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        assert x.shape[2] == x.shape[3] == self.resolution\n",
    "        \n",
    "        # Timestep embedding\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = self.temb[0](temb)\n",
    "        temb = nonlinearity(temb)\n",
    "        temb = self.temb[1](temb)\n",
    "        \n",
    "        # Initial convolution\n",
    "        h = self.conv_in(x)\n",
    "        hs = [h]\n",
    "        \n",
    "        # Downsampling\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "                if len(self.down[i_level].attn) > 0:\n",
    "                    h = self.down[i_level].attn[i_block](h)\n",
    "                hs.append(h)\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "        \n",
    "        # Middle\n",
    "        h = hs[-1]\n",
    "        h = self.mid.block_1(h, temb)\n",
    "        h = self.mid.attn_1(h)\n",
    "        h = self.mid.block_2(h, temb)\n",
    "        \n",
    "        # Upsampling\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            for i_block in range(self.num_res_blocks + 1):\n",
    "                h = self.up[i_level].block[i_block](\n",
    "                    torch.cat([h, hs.pop()], dim=1), temb\n",
    "                )\n",
    "                if len(self.up[i_level].attn) > 0:\n",
    "                    h = self.up[i_level].attn[i_block](h)\n",
    "            if i_level != 0:\n",
    "                h = self.up[i_level].upsample(h)\n",
    "        \n",
    "        # Final output\n",
    "        h = self.norm_out(h)\n",
    "        h = nonlinearity(h)\n",
    "        h = self.conv_out(h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "# Test model\n",
    "model = UNetDDPM(in_channels=2, out_channels=1, ch=32, resolution=256)\n",
    "print(f\"âœ“ UNetDDPM model created\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bd93f",
   "metadata": {},
   "source": [
    "## Noise Scheduling & Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha(beta, t):\n",
    "    \"\"\"Compute cumulative product of alphas up to timestep t\"\"\"\n",
    "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
    "    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)\n",
    "    return a\n",
    "\n",
    "def get_beta_schedule(beta_schedule, beta_start=0.0001, beta_end=0.02, num_diffusion_timesteps=1000):\n",
    "    \"\"\"Get noise schedule for diffusion process\"\"\"\n",
    "    if beta_schedule == 'linear':\n",
    "        betas = torch.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=torch.float64)\n",
    "    elif beta_schedule == 'scaled_linear':\n",
    "        betas = torch.linspace(beta_start**0.5, beta_end**0.5, num_diffusion_timesteps, dtype=torch.float64) ** 2\n",
    "    else:\n",
    "        raise NotImplementedError(f\"beta schedule {beta_schedule} unknown\")\n",
    "    \n",
    "    return betas\n",
    "\n",
    "def generalized_steps(x, seq, model, b, device, eta=0.0):\n",
    "    \"\"\"\n",
    "    Fast-DDPM sampling with generalized schedule.\n",
    "    x: noisy sample (B, C, H, W)\n",
    "    seq: list of timesteps to use for sampling\n",
    "    model: UNet model\n",
    "    b: beta schedule\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        n = x.size(0)\n",
    "        seq_next = [-1] + list(seq[:-1])\n",
    "        x0_preds = []\n",
    "        xs = [x]\n",
    "        \n",
    "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
    "            t = (torch.ones(n) * i).to(device)\n",
    "            next_t = (torch.ones(n) * j).to(device)\n",
    "            at = compute_alpha(b, t.long())\n",
    "            at_next = compute_alpha(b, next_t.long())\n",
    "            \n",
    "            xt = xs[-1].to(device)\n",
    "            et = model(xt, t)\n",
    "            \n",
    "            x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
    "            x0_preds.append(x0_t.to('cpu'))\n",
    "            \n",
    "            # Equation (12) from DDIM paper\n",
    "            c1 = eta * ((1 - at / at_next) * (1 - at_next) / (1 - at)).sqrt()\n",
    "            c2 = ((1 - at_next) - c1 ** 2).sqrt()\n",
    "            \n",
    "            xt_next = at_next.sqrt() * x0_t + c1 * torch.randn_like(x) + c2 * et\n",
    "            xs.append(xt_next.to('cpu'))\n",
    "    \n",
    "    return xs, x0_preds\n",
    "\n",
    "class FastDDPMScheduler:\n",
    "    \"\"\"\n",
    "    Manages timestep schedules for Fast-DDPM.\n",
    "    Supports uniform and non-uniform sampling strategies.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.scheduler_type = scheduler_type\n",
    "        \n",
    "        if scheduler_type == 'uniform':\n",
    "            # Uniform spacing\n",
    "            skip = num_timesteps // num_inference_steps\n",
    "            self.timesteps = np.arange(0, num_timesteps, skip)\n",
    "        elif scheduler_type == 'non-uniform':\n",
    "            # Non-uniform: emphasize early denoising\n",
    "            # Default 10 steps from Fast-DDPM paper\n",
    "            if num_inference_steps == 10:\n",
    "                self.timesteps = np.array([0, 99, 199, 299, 399, 499, 599, 699, 799, 999])\n",
    "            else:\n",
    "                # Custom non-uniform schedule\n",
    "                num_1 = int(num_inference_steps * 0.4)\n",
    "                num_2 = int(num_inference_steps * 0.6)\n",
    "                stage_1 = np.linspace(0, 699, num_1 + 1)[:-1]\n",
    "                stage_2 = np.linspace(699, 999, num_2)\n",
    "                self.timesteps = np.concatenate([stage_1, stage_2]).astype(int)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")\n",
    "    \n",
    "    def get_timesteps(self):\n",
    "        return torch.from_numpy(self.timesteps).long()\n",
    "\n",
    "# Test scheduler\n",
    "scheduler_uniform = FastDDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='uniform')\n",
    "scheduler_nonuniform = FastDDPMScheduler(num_timesteps=1000, num_inference_steps=10, scheduler_type='non-uniform')\n",
    "\n",
    "print(f\"âœ“ Schedulers created\")\n",
    "print(f\"  Uniform timesteps: {scheduler_uniform.get_timesteps().numpy()}\")\n",
    "print(f\"  Non-uniform timesteps: {scheduler_nonuniform.get_timesteps().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136eb189",
   "metadata": {},
   "source": [
    "## Training Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29695eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data generators from src\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "from ModelDataGenerator import build_dataloader\n",
    "\n",
    "# Load data for training\n",
    "print(\"ðŸ“¥ Loading training data...\")\n",
    "train_loader = build_dataloader(split='train', batch_size=4, augment=True, num_workers=4)\n",
    "val_loader = build_dataloader(split='val', batch_size=4, augment=False, num_workers=4)\n",
    "test_loader = build_dataloader(split='test', batch_size=1, augment=False, num_workers=0)\n",
    "\n",
    "print(f\"âœ“ Data loaded\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Verify data shape\n",
    "for (pre, post), mid in train_loader:\n",
    "    print(f\"  Batch shape: pre={pre.shape}, post={post.shape}, mid={mid.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5714dcf",
   "metadata": {},
   "source": [
    "## Fast-DDPM Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e38fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training components\n",
    "model = UNetDDPM(\n",
    "    in_channels=2,  # pre and post slices\n",
    "    model_channels=32,\n",
    "    out_channels=1,  # predict middle slice\n",
    "    num_res_blocks=2,\n",
    "    attention_resolutions=[16]  # attention at 16x16 resolution\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize diffusion process\n",
    "num_timesteps = 1000\n",
    "beta_schedule = get_beta_schedule(\"linear\", num_timesteps, device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# EMA (Exponential Moving Average) for model weights\n",
    "ema_rate = 0.9999\n",
    "ema_model = UNetDDPM(\n",
    "    in_channels=2,\n",
    "    model_channels=32,\n",
    "    out_channels=1,\n",
    "    num_res_blocks=2,\n",
    "    attention_resolutions=[16]\n",
    ").to(device)\n",
    "ema_model.load_state_dict(model.state_dict())\n",
    "\n",
    "def update_ema(model, ema_model, ema_rate):\n",
    "    \"\"\"Update EMA model weights\"\"\"\n",
    "    for param, ema_param in zip(model.parameters(), ema_model.parameters()):\n",
    "        ema_param.data = ema_param.data * ema_rate + param.data * (1 - ema_rate)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, beta_schedule, device, ema_model=None, ema_rate=0.9999):\n",
    "    \"\"\"Train one epoch with antithetic sampling for variance reduction\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pre, post) in enumerate(train_loader):\n",
    "        pre = pre.to(device)  # (B, 1, 256, 256)\n",
    "        post = post.to(device)  # (B, 1, 256, 256)\n",
    "        \n",
    "        # Concatenate pre and post as input\n",
    "        x_t = torch.cat([pre, post], dim=1)  # (B, 2, 256, 256)\n",
    "        \n",
    "        # Antithetic sampling: use pairs of opposite timesteps for variance reduction\n",
    "        batch_size = x_t.shape[0]\n",
    "        # Sample timesteps (uniform) for first half\n",
    "        t_half = torch.randint(0, num_timesteps, size=(batch_size // 2 + 1,), device=device)\n",
    "        # Create antithetic pair (opposite timesteps)\n",
    "        t = torch.cat([t_half, num_timesteps - 1 - t_half])[:batch_size]\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn_like(pre)  # (B, 1, 256, 256)\n",
    "        \n",
    "        # Compute alpha_bar(t) for each timestep\n",
    "        alpha_bar_t = compute_alpha(beta_schedule, t)  # (B,)\n",
    "        \n",
    "        # Add noise to image: x_t = sqrt(alpha_bar_t) * x + sqrt(1 - alpha_bar_t) * noise\n",
    "        noisy_x = (\n",
    "            alpha_bar_t.sqrt().view(-1, 1, 1, 1) * pre +\n",
    "            (1.0 - alpha_bar_t).sqrt().view(-1, 1, 1, 1) * noise\n",
    "        )  # (B, 1, 256, 256)\n",
    "        \n",
    "        # Forward pass through model (predict noise)\n",
    "        input_x = torch.cat([noisy_x, post], dim=1)  # (B, 2, 256, 256)\n",
    "        predicted_noise = model(input_x, t)  # (B, 1, 256, 256)\n",
    "        \n",
    "        # Loss: MSE between predicted noise and actual noise\n",
    "        loss = torch.nn.functional.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.functional.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update EMA model\n",
    "        if ema_model is not None:\n",
    "            update_ema(model, ema_model, ema_rate)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_loader)}: Loss = {loss.item():.6f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, beta_schedule, device):\n",
    "    \"\"\"Validate model on validation set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pre, post in val_loader:\n",
    "            pre = pre.to(device)\n",
    "            post = post.to(device)\n",
    "            x_t = torch.cat([pre, post], dim=1)\n",
    "            \n",
    "            # Sample random timesteps\n",
    "            batch_size = x_t.shape[0]\n",
    "            t = torch.randint(0, num_timesteps, size=(batch_size,), device=device)\n",
    "            \n",
    "            # Sample noise and create noisy version\n",
    "            noise = torch.randn_like(pre)\n",
    "            alpha_bar_t = compute_alpha(beta_schedule, t)\n",
    "            noisy_x = (\n",
    "                alpha_bar_t.sqrt().view(-1, 1, 1, 1) * pre +\n",
    "                (1.0 - alpha_bar_t).sqrt().view(-1, 1, 1, 1) * noise\n",
    "            )\n",
    "            \n",
    "            # Forward pass\n",
    "            input_x = torch.cat([noisy_x, post], dim=1)\n",
    "            predicted_noise = model(input_x, t)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = torch.nn.functional.mse_loss(predicted_noise, noise)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, beta_schedule, device, ema_model, ema_rate)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, beta_schedule, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        print(f\"  â†’ Best validation loss! Saving checkpoint...\")\n",
    "        torch.save({\n",
    "            'model_state': model.state_dict(),\n",
    "            'ema_state': ema_model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss\n",
    "        }, 'fastddpm_best.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nTraining complete! Best validation loss: {best_val_loss:.6f}\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('fastddpm_best.pth')\n",
    "ema_model.load_state_dict(checkpoint['ema_state'])\n",
    "print(\"Loaded best EMA model for inference\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2348b1",
   "metadata": {},
   "source": [
    "## Inference & Evaluation with Different Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14715fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, pre, post, beta_schedule, scheduler_type='non-uniform', device=None):\n",
    "    \"\"\"\n",
    "    Run inference using generalized_steps sampling\n",
    "    Args:\n",
    "        model: diffusion model\n",
    "        pre: pre-slice (1, 256, 256)\n",
    "        post: post-slice (1, 256, 256)\n",
    "        beta_schedule: beta schedule tensor\n",
    "        scheduler_type: 'uniform' or 'non-uniform'\n",
    "        device: device to run on\n",
    "    Returns:\n",
    "        predicted middle slice (1, 256, 256)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create batch of 1\n",
    "    pre = pre.unsqueeze(0).to(device)  # (1, 1, 256, 256)\n",
    "    post = post.unsqueeze(0).to(device)  # (1, 1, 256, 256)\n",
    "    x = torch.cat([pre, post], dim=1)  # (1, 2, 256, 256)\n",
    "    \n",
    "    # Initialize noise\n",
    "    x_t = torch.randn(1, 1, 256, 256, device=device)  # Start from pure noise\n",
    "    \n",
    "    # Get scheduler\n",
    "    scheduler = FastDDPMScheduler(num_timesteps=1000)\n",
    "    if scheduler_type == 'uniform':\n",
    "        timesteps = scheduler.get_uniform_schedule(skip=100)  # 10 steps\n",
    "    else:  # non-uniform\n",
    "        timesteps = scheduler.get_non_uniform_schedule()  # Fast-DDPM schedule\n",
    "    \n",
    "    # Reverse diffusion process\n",
    "    with torch.no_grad():\n",
    "        for idx, t_cur in enumerate(timesteps):\n",
    "            # Time embedding\n",
    "            t = torch.tensor([t_cur] * 1, device=device)\n",
    "            \n",
    "            # Model prediction\n",
    "            input_x = torch.cat([x_t, post], dim=1)\n",
    "            noise_pred = model(input_x, t)\n",
    "            \n",
    "            # Denoising step using generalized_steps logic\n",
    "            # Get noise schedule values\n",
    "            if idx < len(timesteps) - 1:\n",
    "                t_next = timesteps[idx + 1]\n",
    "            else:\n",
    "                t_next = 0\n",
    "            \n",
    "            # Simplified DDIM step (eta=0 for deterministic)\n",
    "            alpha_t = compute_alpha(beta_schedule, t)\n",
    "            alpha_next = compute_alpha(beta_schedule, torch.tensor([t_next], device=device))\n",
    "            \n",
    "            sigma_t = 0.0  # eta=0, deterministic\n",
    "            alpha_t_next = alpha_next.view(-1, 1, 1, 1)\n",
    "            alpha_t = alpha_t.view(-1, 1, 1, 1)\n",
    "            \n",
    "            # x_t = (x_t - sqrt(1-alpha_t) * noise_pred) / sqrt(alpha_t)\n",
    "            x_t = (x_t - (1 - alpha_t).sqrt() * noise_pred) / alpha_t.sqrt()\n",
    "            x_t = x_t * alpha_t_next.sqrt() + (1 - alpha_t_next).sqrt() * noise_pred\n",
    "            \n",
    "            if (idx + 1) % max(1, len(timesteps) // 10) == 0:\n",
    "                print(f\"  Step {idx + 1}/{len(timesteps)}\")\n",
    "    \n",
    "    # Clip to valid range\n",
    "    x_t = torch.clamp(x_t, -1.0, 1.0)\n",
    "    \n",
    "    return x_t.squeeze(0).cpu()\n",
    "\n",
    "# Compute metrics function\n",
    "def compute_metrics(predictions, ground_truth):\n",
    "    \"\"\"Compute SSIM and PSNR between predictions and ground truth\"\"\"\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    \n",
    "    preds = predictions.numpy() if isinstance(predictions, torch.Tensor) else predictions\n",
    "    gts = ground_truth.numpy() if isinstance(ground_truth, torch.Tensor) else ground_truth\n",
    "    \n",
    "    # Normalize to [0, 1] if needed\n",
    "    if preds.min() < 0:\n",
    "        preds = (preds + 1) / 2\n",
    "    if gts.min() < 0:\n",
    "        gts = (gts + 1) / 2\n",
    "    \n",
    "    # Compute SSIM\n",
    "    ssim_val = ssim(gts, preds, data_range=1.0)\n",
    "    \n",
    "    # Compute PSNR (max value is 1.0)\n",
    "    mse = np.mean((preds - gts) ** 2)\n",
    "    psnr_val = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else 100\n",
    "    \n",
    "    return ssim_val, psnr_val\n",
    "\n",
    "# Evaluation on test set with both schedulers\n",
    "print(\"Running inference on test set with different schedulers...\\n\")\n",
    "\n",
    "results = {\n",
    "    'uniform': {'ssim': [], 'psnr': []},\n",
    "    'non_uniform': {'ssim': [], 'psnr': []}\n",
    "}\n",
    "\n",
    "test_samples = []\n",
    "max_samples = 20  # Limit to 20 samples for speed\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample_idx, (pre, post, mid) in enumerate(test_loader):\n",
    "        if sample_idx >= max_samples:\n",
    "            break\n",
    "        \n",
    "        print(f\"Processing sample {sample_idx + 1}/{min(max_samples, len(test_loader))}...\")\n",
    "        \n",
    "        # Try uniform scheduler\n",
    "        try:\n",
    "            pred_uniform = inference(ema_model, pre.squeeze(), post.squeeze(), \n",
    "                                     beta_schedule, scheduler_type='uniform', device=device)\n",
    "            ssim_u, psnr_u = compute_metrics(pred_uniform, mid.squeeze())\n",
    "            results['uniform']['ssim'].append(ssim_u)\n",
    "            results['uniform']['psnr'].append(psnr_u)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error with uniform: {e}\")\n",
    "            ssim_u, psnr_u = None, None\n",
    "        \n",
    "        # Try non-uniform scheduler\n",
    "        try:\n",
    "            pred_nonuniform = inference(ema_model, pre.squeeze(), post.squeeze(), \n",
    "                                       beta_schedule, scheduler_type='non-uniform', device=device)\n",
    "            ssim_nu, psnr_nu = compute_metrics(pred_nonuniform, mid.squeeze())\n",
    "            results['non_uniform']['ssim'].append(ssim_nu)\n",
    "            results['non_uniform']['psnr'].append(psnr_nu)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error with non-uniform: {e}\")\n",
    "            ssim_nu, psnr_nu = None, None\n",
    "        \n",
    "        if ssim_u and ssim_nu:\n",
    "            print(f\"  Uniform - SSIM: {ssim_u:.4f}, PSNR: {psnr_u:.2f}\")\n",
    "            print(f\"  Non-uniform - SSIM: {ssim_nu:.4f}, PSNR: {psnr_nu:.2f}\\n\")\n",
    "        \n",
    "        # Store first few samples for visualization\n",
    "        if sample_idx < 3:\n",
    "            test_samples.append({\n",
    "                'pre': pre.squeeze(),\n",
    "                'post': post.squeeze(),\n",
    "                'mid_gt': mid.squeeze(),\n",
    "                'pred_uniform': pred_uniform if 'pred_uniform' in locals() else None,\n",
    "                'pred_nonuniform': pred_nonuniform if 'pred_nonuniform' in locals() else None\n",
    "            })\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if results['uniform']['ssim']:\n",
    "    uniform_ssim_mean = np.mean(results['uniform']['ssim'])\n",
    "    uniform_ssim_std = np.std(results['uniform']['ssim'])\n",
    "    uniform_psnr_mean = np.mean(results['uniform']['psnr'])\n",
    "    uniform_psnr_std = np.std(results['uniform']['psnr'])\n",
    "    \n",
    "    print(f\"Uniform Scheduler (10-step):\")\n",
    "    print(f\"  SSIM: {uniform_ssim_mean:.4f} Â± {uniform_ssim_std:.4f}\")\n",
    "    print(f\"  PSNR: {uniform_psnr_mean:.2f} Â± {uniform_psnr_std:.2f}\")\n",
    "\n",
    "if results['non_uniform']['ssim']:\n",
    "    nonuniform_ssim_mean = np.mean(results['non_uniform']['ssim'])\n",
    "    nonuniform_ssim_std = np.std(results['non_uniform']['ssim'])\n",
    "    nonuniform_psnr_mean = np.mean(results['non_uniform']['psnr'])\n",
    "    nonuniform_psnr_std = np.std(results['non_uniform']['psnr'])\n",
    "    \n",
    "    print(f\"\\nNon-Uniform Scheduler (Fast-DDPM):\")\n",
    "    print(f\"  SSIM: {nonuniform_ssim_mean:.4f} Â± {nonuniform_ssim_std:.4f}\")\n",
    "    print(f\"  PSNR: {nonuniform_psnr_mean:.2f} Â± {nonuniform_psnr_std:.2f}\")\n",
    "\n",
    "if results['uniform']['ssim'] and results['non_uniform']['ssim']:\n",
    "    ssim_improvement = (nonuniform_ssim_mean - uniform_ssim_mean) / uniform_ssim_mean * 100\n",
    "    psnr_improvement = (nonuniform_psnr_mean - uniform_psnr_mean) / uniform_psnr_mean * 100\n",
    "    print(f\"\\nNon-Uniform vs Uniform Improvement:\")\n",
    "    print(f\"  SSIM: {ssim_improvement:+.2f}%\")\n",
    "    print(f\"  PSNR: {psnr_improvement:+.2f}%\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa2183",
   "metadata": {},
   "source": [
    "## Visualization & Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Training loss curve\n",
    "axes[0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('MSE Loss', fontsize=12)\n",
    "axes[0].set_title('Fast-DDPM Training Progress', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Scheduler comparison\n",
    "if results['uniform']['ssim'] and results['non_uniform']['ssim']:\n",
    "    schedulers = ['Uniform\\n(skip=100)', 'Non-Uniform\\n(Fast-DDPM)']\n",
    "    ssim_means = [uniform_ssim_mean, nonuniform_ssim_mean]\n",
    "    ssim_stds = [uniform_ssim_std, nonuniform_ssim_std]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    x_pos = np.arange(len(schedulers))\n",
    "    bars = axes[1].bar(x_pos, ssim_means, yerr=ssim_stds, capsize=5, \n",
    "                       color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    axes[1].set_ylabel('SSIM', fontsize=12)\n",
    "    axes[1].set_title('Scheduler Comparison (Test Set)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xticks(x_pos)\n",
    "    axes[1].set_xticklabels(schedulers, fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1].set_ylim([0, 1.0])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, mean, std) in enumerate(zip(bars, ssim_means, ssim_stds)):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height + std + 0.02,\n",
    "                    f'{mean:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fastddpm_training_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training curves saved to 'fastddpm_training_results.png'\")\n",
    "\n",
    "# Visualize sample predictions\n",
    "if test_samples:\n",
    "    num_samples = len(test_samples)\n",
    "    \n",
    "    # Normalize to [0, 1] for visualization\n",
    "    def normalize_for_display(x):\n",
    "        x = x.numpy() if isinstance(x, torch.Tensor) else x\n",
    "        if x.min() < 0:\n",
    "            x = (x + 1) / 2\n",
    "        return np.clip(x, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 5, figsize=(15, 3*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, sample in enumerate(test_samples):\n",
    "        # Pre-slice\n",
    "        pre_norm = normalize_for_display(sample['pre'])\n",
    "        axes[row, 0].imshow(pre_norm, cmap='gray')\n",
    "        axes[row, 0].set_title('Pre-slice', fontsize=11, fontweight='bold')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # Post-slice\n",
    "        post_norm = normalize_for_display(sample['post'])\n",
    "        axes[row, 1].imshow(post_norm, cmap='gray')\n",
    "        axes[row, 1].set_title('Post-slice', fontsize=11, fontweight='bold')\n",
    "        axes[row, 1].axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        gt_norm = normalize_for_display(sample['mid_gt'])\n",
    "        axes[row, 2].imshow(gt_norm, cmap='gray')\n",
    "        axes[row, 2].set_title('Ground Truth', fontsize=11, fontweight='bold')\n",
    "        axes[row, 2].axis('off')\n",
    "        \n",
    "        # Prediction - Uniform\n",
    "        if sample['pred_uniform'] is not None:\n",
    "            pred_u_norm = normalize_for_display(sample['pred_uniform'])\n",
    "            axes[row, 3].imshow(pred_u_norm, cmap='gray')\n",
    "            axes[row, 3].set_title('Pred (Uniform)', fontsize=11, fontweight='bold')\n",
    "            axes[row, 3].axis('off')\n",
    "        else:\n",
    "            axes[row, 3].text(0.5, 0.5, 'No prediction', ha='center', va='center')\n",
    "            axes[row, 3].axis('off')\n",
    "        \n",
    "        # Prediction - Non-uniform\n",
    "        if sample['pred_nonuniform'] is not None:\n",
    "            pred_nu_norm = normalize_for_display(sample['pred_nonuniform'])\n",
    "            axes[row, 4].imshow(pred_nu_norm, cmap='gray')\n",
    "            axes[row, 4].set_title('Pred (Non-Uniform)', fontsize=11, fontweight='bold')\n",
    "            axes[row, 4].axis('off')\n",
    "        else:\n",
    "            axes[row, 4].text(0.5, 0.5, 'No prediction', ha='center', va='center')\n",
    "            axes[row, 4].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fastddpm_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved predictions for {num_samples} samples to 'fastddpm_predictions.png'\")\n",
    "\n",
    "# Comparison with baseline models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FAST-DDPM vs OTHER MODELS (from README)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_results = {\n",
    "    'Model': ['UNet', 'DeepCNN', 'UNet-GAN', 'Progressive UNet', 'FastDDPM (Uniform)', 'FastDDPM (Non-Uniform)'],\n",
    "    'SSIM': [0.711, 0.710, 0.760, 0.724, \n",
    "             uniform_ssim_mean if results['uniform']['ssim'] else 'N/A',\n",
    "             nonuniform_ssim_mean if results['non_uniform']['ssim'] else 'N/A'],\n",
    "    'PSNR': [23.61, 23.61, 28.57, 26.97,\n",
    "             uniform_psnr_mean if results['uniform']['psnr'] else 'N/A',\n",
    "             nonuniform_psnr_mean if results['non_uniform']['psnr'] else 'N/A']\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df_comparison = pd.DataFrame(baseline_results)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ“ Fast-DDPM implementation complete!\")\n",
    "print(\"âœ“ Key improvements from standard DDPM:\")\n",
    "print(\"  - Sinusoidal positional embeddings for timesteps\")\n",
    "print(\"  - Multi-resolution attention blocks (AttnBlock at 16x resolution)\")\n",
    "print(\"  - Non-uniform noise schedule (faster convergence)\")\n",
    "print(\"  - Generalized DDIM sampling (10 steps instead of 1000)\")\n",
    "print(\"  - Antithetic sampling during training (variance reduction)\")\n",
    "print(\"âœ“ Results saved: 'fastddpm_training_results.png', 'fastddpm_predictions.png'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
